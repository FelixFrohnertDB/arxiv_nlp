{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b06eeb-b7bc-4787-a65f-de3ef301bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf, ccf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311720ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_cosine(vec1, vec2):\n",
    "    cosine_similarity_arr = []\n",
    "    for v1,v2 in zip(vec1, vec2):\n",
    "        cosine_similarity = np.dot(v1, v2)/(np.linalg.norm(v1)* np.linalg.norm(v2))\n",
    "        cosine_similarity_arr.append(cosine_similarity)\n",
    "    return np.array(cosine_similarity_arr)\n",
    "\n",
    "def keep_words_with_underscore(input_string):\n",
    "    # Define a regular expression pattern to match words with underscores\n",
    "    pattern = r'\\b\\w*_[\\w_]*\\b'\n",
    "\n",
    "    # Use re.findall to extract words that match the pattern\n",
    "    matching_words = re.findall(pattern, input_string)\n",
    "\n",
    "    # Join the matching words to form the final string\n",
    "    result = ' '.join(matching_words)\n",
    "    return result\n",
    "\n",
    "def update_co_occurrences(word_year_list,word_co_occurrences):\n",
    "    # Iterate through the words in the list\n",
    "    word_list, year = word_year_list\n",
    "    \n",
    "    for word in word_list:\n",
    "        # If the word is not already in the dictionary, add it with an empty list\n",
    "        if word not in word_co_occurrences:\n",
    "            word_co_occurrences[word] = {}\n",
    "        \n",
    "        # Add words from the list to the co-occurrence list for the current word\n",
    "        for other_word in word_list:\n",
    "            # if other_word != word and other_word not in word_co_occurrences[word]:\n",
    "            #     word_co_occurrences[word].append(other_word)\n",
    "            if other_word != word and other_word not in word_co_occurrences[word]:\n",
    "                word_co_occurrences[word][other_word] = [year] \n",
    "            \n",
    "            elif other_word != word and other_word in word_co_occurrences[word]:\n",
    "                # word_co_occurrences[word][other_word][0] +=1\n",
    "                word_co_occurrences[word][other_word].append(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469d38d",
   "metadata": {},
   "source": [
    "### Get Word Co-Occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6094b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts which were tracked (10235,)\n",
      "Abstracts (66839,)\n",
      "Year associated to abstract (66839,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63633/63633 [00:02<00:00, 29878.70it/s]\n"
     ]
    }
   ],
   "source": [
    "concept_filtered_arr = np.load(\"saved_files/overlapping_filtered_5_concepts.npy\")\n",
    "ngram_abstracts = np.load(\"saved_files/ngram_abstracts.npy\", mmap_mode=\"r\")\n",
    "saved_year_arr = np.load(\"saved_files/year_arr.npy\", mmap_mode=\"r\")\n",
    "\n",
    "print(\"Concepts which were tracked\",concept_filtered_arr.shape)\n",
    "print(\"Abstracts\",ngram_abstracts.shape)\n",
    "print(\"Year associated to abstract\",saved_year_arr.shape)\n",
    "\n",
    "phys_filtered_concept_dict = {k:1 for k in concept_filtered_arr}\n",
    "ocurr_arr = []\n",
    "for abstract, year in zip(ngram_abstracts, saved_year_arr):\n",
    "    temp = keep_words_with_underscore(abstract)\n",
    "    if temp.count(\" \") > 0:\n",
    "        temp = temp.split(\" \") \n",
    "        temp = [s for s in temp if s in phys_filtered_concept_dict]\n",
    "        ocurr_arr.append([list(filter((\"_\").__ne__, temp)),year])\n",
    "                        \n",
    "word_co_occurrences = {}\n",
    "\n",
    "for word_list in tqdm(ocurr_arr):\n",
    "    update_co_occurrences(word_list,word_co_occurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d927ce7",
   "metadata": {},
   "source": [
    "### Get Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f4116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model_for_year(year):\n",
    "#     return Word2Vec.load(f\"saved_models/re_model_year_{year}.model\")\n",
    "\n",
    "# load = True \n",
    "# if load:\n",
    "c_inx_arr = np.memmap(\"saved_files/embedding_concept_arr.dat\",shape=(10235,), dtype=\"<U55\")\n",
    "c_encoding_arr = np.memmap(\"saved_files/embedding_vector_arr.dat\",shape=(10235, 30, 128), dtype=np.float64)\n",
    "\n",
    "# else:\n",
    "#     # Initialize dictionaries and counters\n",
    "#     c_dict = {}\n",
    "#     cnt_0, cnt_1 = 0, 0\n",
    "\n",
    "#     # Get the unique years\n",
    "#     unique_years = np.unique(saved_year_arr)\n",
    "\n",
    "#     # Iterate over each year and load the corresponding model\n",
    "#     for year in tqdm(unique_years):\n",
    "#         loaded_w2v = load_model_for_year(year)\n",
    "\n",
    "#         # Iterate over each concept in the filtered concept dictionary\n",
    "#         for c in phys_filtered_concept_dict:\n",
    "#             if c not in c_dict:\n",
    "#                 c_dict[c] = {}\n",
    "\n",
    "#             # If the concept is already recorded for the current year, skip it\n",
    "#             if year in c_dict[c]:\n",
    "#                 continue\n",
    "\n",
    "#             try:\n",
    "#                 # Get the vector encoding for the concept\n",
    "#                 vec_enc = loaded_w2v.wv.get_vector(c)\n",
    "#                 c_dict[c][year] = vec_enc\n",
    "#                 cnt_0 += 1\n",
    "#             except KeyError:  # Catch specific exception for missing key\n",
    "#                 cnt_1 += 1\n",
    "#                 pass\n",
    "\n",
    "#     print(f\"Found {cnt_0} vectors, missed {cnt_1} vectors.\")\n",
    "\n",
    "#     # Initialize lists for lengths and concept indices\n",
    "#     len_arr, len_new_arr, concept_inx_arr = [], [], []\n",
    "\n",
    "#     # Iterate over each concept to fill missing years with the first available vector\n",
    "#     for c in tqdm(phys_filtered_concept_dict):\n",
    "#         l = len(c_dict[c])\n",
    "#         len_arr.append(l)\n",
    "\n",
    "#         if l > 0:\n",
    "#             concept_inx_arr.append(c)\n",
    "#             success_years = sorted(c_dict[c].keys())\n",
    "#             first_success_year = success_years[0]\n",
    "\n",
    "#             # Backtrack and fill in the missing years with the first available vector\n",
    "#             for year in unique_years:\n",
    "#                 if year < first_success_year:\n",
    "#                     if year not in c_dict[c]:\n",
    "#                         c_dict[c][year] = c_dict[c][first_success_year]\n",
    "#                 else:\n",
    "#                     break\n",
    "\n",
    "#         len_new_arr.append(len(c_dict[c]))\n",
    "\n",
    "#     concept_inx_arr = np.array(concept_inx_arr)\n",
    "\n",
    "#     # Display the distribution of the number of years filled for each concept\n",
    "#     print(np.unique(len_new_arr, return_counts=True))\n",
    "\n",
    "#     # Prepare the encoding array\n",
    "#     num_concepts = len(c_dict)\n",
    "#     num_years = len(unique_years)\n",
    "#     embedding_dim = 128\n",
    "\n",
    "#     c_encoding_arr = np.zeros((num_concepts, num_years, embedding_dim))\n",
    "#     c_inx_arr = []\n",
    "\n",
    "#     # Fill the encoding array with vectors for each concept and year\n",
    "#     for cnt, (concept, year_vectors) in enumerate(c_dict.items()):\n",
    "#         c_encoding_arr[cnt] = np.array([year_vectors.get(year, np.zeros(embedding_dim)) for year in unique_years])\n",
    "#         c_inx_arr.append(concept)\n",
    "\n",
    "#     c_inx_arr = np.array(c_inx_arr)\n",
    "\n",
    "    \n",
    "#     filename = 'saved_files/embedding_concept_arr.dat'\n",
    "#     memmap_array = np.memmap(filename, dtype=c_inx_arr.dtype, mode='w+', shape=c_inx_arr.shape)\n",
    "#     print(\"shape:\",c_inx_arr.shape)\n",
    "#     memmap_array[:] = c_inx_arr\n",
    "#     memmap_array.flush()\n",
    "\n",
    "#     filename = 'saved_files/embedding_vector_arr.dat'\n",
    "#     memmap_array = np.memmap(filename, dtype=c_encoding_arr.dtype, mode='w+', shape=c_encoding_arr.shape)\n",
    "#     print(\"shape:\",c_encoding_arr.shape)\n",
    "#     memmap_array[:] = c_encoding_arr\n",
    "#     memmap_array.flush()\n",
    "\n",
    "#     stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b26a1",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34a4010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation Vectors for tracked concepts (10235, 30, 128)\n",
      "Concept associted with representation (10235,)\n"
     ]
    }
   ],
   "source": [
    "def get_co_occur_concept_pair_after_year_arr(word_co_occurrences: dict, first_occ_year: int, final_occ_year: int) -> np.ndarray:\n",
    "    co_occur_concept_pair_arr = []\n",
    "    for concept, v in word_co_occurrences.items():\n",
    "        for co_concept, years in v.items():\n",
    "            if np.min(years) >= first_occ_year and np.max(years) <= final_occ_year:\n",
    "                co_occur_concept_pair_arr.append([concept,co_concept])\n",
    "    return np.array(co_occur_concept_pair_arr)\n",
    "\n",
    "def _get_years_range(start: int, end: int) -> np.ndarray:\n",
    "        return (np.unique(saved_year_arr)[start:] if end == -0 \n",
    "                                 else np.unique(saved_year_arr)[start:end])\n",
    "\n",
    "def create_dataset_indexing(data: np.ndarray, word_co_occurrences: dict, year_arr: np.ndarray, c_inx_arr: np.ndarray, \n",
    "                 input_window_size: int = 5, output_window_size: int = 3, offset_to_current_year: int = 1, print_test: bool = False, save=True):\n",
    "    \"\"\"\n",
    "    Dataset indexing for time series data.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The input data.\n",
    "        word_co_occurrences (dict): Dictionary of word co-occurrences.\n",
    "        year_arr (np.ndarray): Array of years.\n",
    "        c_inx_arr (np.ndarray): Array of concept indices.\n",
    "        input_window_size (int, optional): Size of the input window. Defaults to 5.\n",
    "        output_window_size (int, optional): Size of the output window. Defaults to 3.\n",
    "        offset_to_current_year (int, optional): Offset to the current year. Defaults to 1.\n",
    "        print_test (bool, optional): Whether to print test information. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Positive index pair array.\n",
    "        np.ndarray: Negative index pair array.\n",
    "    \"\"\"\n",
    "    train_window_data = data[:, -input_window_size-output_window_size-offset_to_current_year:-output_window_size-offset_to_current_year]\n",
    "    label_year_range = (year_arr[-output_window_size:] if offset_to_current_year == 0 \n",
    "                                else year_arr[-output_window_size-offset_to_current_year:-offset_to_current_year])\n",
    "\n",
    "    co_occur_concept_pair_arr = get_co_occur_concept_pair_after_year_arr(\n",
    "        word_co_occurrences, label_year_range[0], label_year_range[-1])\n",
    "    \n",
    "    print(f\"Training Window: {_get_years_range(-input_window_size-output_window_size-offset_to_current_year, -output_window_size-offset_to_current_year)}\")\n",
    "    print(f\"Label Window: {_get_years_range(-output_window_size-offset_to_current_year, -offset_to_current_year)}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Precompute indices for each unique concept in c_inx_arr\n",
    "    concept_to_indices = {concept: np.where(c_inx_arr == concept)[0] for concept in np.unique(c_inx_arr)}\n",
    "\n",
    "    # Convert word_co_occurrences to a dictionary of sets for fast membership checking\n",
    "    word_co_occurrences_set = {k: set(v) for k, v in word_co_occurrences.items()}\n",
    "\n",
    "    pos_inx_pair_arr = np.zeros((len(co_occur_concept_pair_arr),2), dtype=int)\n",
    "    \n",
    "    for inx, pair in enumerate(co_occur_concept_pair_arr):\n",
    "        pos_inx_pair_arr[inx, 0] = concept_to_indices[pair[0]][0]\n",
    "        pos_inx_pair_arr[inx, 1] = concept_to_indices[pair[1]][0]\n",
    "\n",
    "    print(\"Finished Positives\")\n",
    "\n",
    "    neg_inx_pair_arr = np.zeros((len(co_occur_concept_pair_arr), 2), dtype=int)\n",
    "    checked_pairs = set()\n",
    "    neg_inx = 0\n",
    "\n",
    "    while neg_inx < len(pos_inx_pair_arr):\n",
    "        sampled_pair = tuple(np.random.choice(train_window_data.shape[0], size=2, replace=False))\n",
    "        \n",
    "        # Ensure the sampled pair is not the same and hasn't been checked before\n",
    "        if sampled_pair not in checked_pairs:\n",
    "            checked_pairs.add(sampled_pair)\n",
    "            concept_0, concept_1 = c_inx_arr[sampled_pair[0]], c_inx_arr[sampled_pair[1]]\n",
    "\n",
    "            if concept_1 not in word_co_occurrences_set.get(concept_0, set()):\n",
    "                neg_inx_pair_arr[neg_inx, 0] = concept_to_indices[concept_0][0]\n",
    "                neg_inx_pair_arr[neg_inx, 1] = concept_to_indices[concept_1][0]\n",
    "                neg_inx += 1\n",
    "    print(\"Finished Negatives\")\n",
    "\n",
    "    if print_test:\n",
    "        save_pos_arr = [word_co_occurrences[c_inx_arr[pos_inx_pair_arr[_][0]]][c_inx_arr[pos_inx_pair_arr[_][1]]] for _ in range(len(pos_inx_pair_arr))]\n",
    "        save_neg_arr = [c_inx_arr[neg_inx_pair_arr[_][1]] in word_co_occurrences[c_inx_arr[neg_inx_pair_arr[_][0]]] for _ in range(len(neg_inx_pair_arr))]\n",
    "\n",
    "        save_pos_arr = [x for xs in save_pos_arr for x in xs]\n",
    "        \n",
    "        print(\"Positive: Expect to be years: \", np.unique(save_pos_arr))\n",
    "        print(\"Negative: Expect to be 0: \", np.sum(save_neg_arr))\n",
    "\n",
    "    if save:\n",
    "        np.save(f\"saved_files/train_pos_inx_pair_arr_{input_window_size}_{output_window_size}_{offset_to_current_year}\", pos_inx_pair_arr)\n",
    "        np.save(f\"saved_files/train_neg_inx_pair_arr_{input_window_size}_{output_window_size}_{offset_to_current_year}\", neg_inx_pair_arr)\n",
    "\n",
    "    return pos_inx_pair_arr, neg_inx_pair_arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Representation Vectors for tracked concepts\",c_encoding_arr.shape)\n",
    "print(\"Concept associted with representation\", c_inx_arr.shape)\n",
    "scaler = StandardScaler()\n",
    "reshaped_data = c_encoding_arr.reshape(-1, c_encoding_arr.shape[-1])  \n",
    "normalized_data = scaler.fit_transform(reshaped_data)\n",
    "encoding_data = normalized_data.reshape(c_encoding_arr.shape)\n",
    "\n",
    "# load = False \n",
    "# if not load:\n",
    "    \n",
    "# else:\n",
    "# train_pos_inx_pair_arr_5_3_3 = np.load(f\"saved_files/train_pos_inx_pair_arr_{seq_length}_{out_length}_3.npy\")\n",
    "# train_neg_inx_pair_arr_5_3_3 = np.load(f\"saved_files/train_neg_inx_pair_arr_{seq_length}_{out_length}_3.npy\")\n",
    "\n",
    "# train_pos_inx_pair_arr_5_3_0 = np.load(f\"saved_files/train_pos_inx_pair_arr_{seq_length}_{out_length}_0.npy\")\n",
    "# train_neg_inx_pair_arr_5_3_0 = np.load(f\"saved_files/train_neg_inx_pair_arr_{seq_length}_{out_length}_0.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b17828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPairDataset(Dataset):\n",
    "    def __init__(self, train_window_data, pair_arr, labels, input_window_size, output_window_size, offset_to_current_year):\n",
    "        self.train_window_data = train_window_data[:, -input_window_size-output_window_size-offset_to_current_year:-output_window_size-offset_to_current_year]\n",
    "        self.pair_arr = pair_arr\n",
    "        self.labels = labels\n",
    "        self.shape = self.train_window_data.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pair_arr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inx_0, inx_1 = self.pair_arr[idx]\n",
    "        label = self.labels[idx]\n",
    "        enc_0 = self.train_window_data[inx_0]\n",
    "        enc_1 = self.train_window_data[inx_1]\n",
    "        enc_01 = np.concatenate((enc_0, enc_1), axis=-1)\n",
    "        return torch.from_numpy(enc_01), torch.tensor([label], dtype=torch.float32), inx_0, inx_1 \n",
    "\n",
    "def create_train_val_datasets(train_window_data, pos_inx_pair_arr, neg_inx_pair_arr, input_window_size, output_window_size, offset_to_current_year, test_size=0.2, random_state=42):\n",
    "    # Create labels\n",
    "    pos_labels = np.ones(len(pos_inx_pair_arr))\n",
    "    neg_labels = np.zeros(len(neg_inx_pair_arr))\n",
    "    \n",
    "    # Concatenate positive and negative pairs and labels\n",
    "    all_pairs = np.vstack((pos_inx_pair_arr, neg_inx_pair_arr))\n",
    "    all_labels = np.concatenate((pos_labels, neg_labels))\n",
    "    \n",
    "    # Split indices into training and test sets\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        np.arange(len(all_pairs)), test_size=test_size, random_state=random_state, stratify=all_labels\n",
    "    )\n",
    "    \n",
    "    # Create training and test datasets\n",
    "    train_dataset = CustomPairDataset(train_window_data, all_pairs[train_idx], all_labels[train_idx], input_window_size, output_window_size, offset_to_current_year)\n",
    "    test_dataset = CustomPairDataset(train_window_data, all_pairs[test_idx], all_labels[test_idx], input_window_size, output_window_size, offset_to_current_year)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def create_test_datasets(train_window_data, pos_inx_pair_arr, neg_inx_pair_arr, input_window_size, output_window_size, offset_to_current_year):\n",
    "    # Create labels\n",
    "    pos_labels = np.ones(len(pos_inx_pair_arr))\n",
    "    neg_labels = np.zeros(len(neg_inx_pair_arr))\n",
    "    \n",
    "    # Concatenate positive and negative pairs and labels\n",
    "    all_pairs = np.vstack((pos_inx_pair_arr, neg_inx_pair_arr))\n",
    "    all_labels = np.concatenate((pos_labels, neg_labels))\n",
    "     \n",
    "    return CustomPairDataset(train_window_data, all_pairs, all_labels, input_window_size, output_window_size, offset_to_current_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e02f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(f\"Training Window: {_get_years_range(-5-3-3, -3-3)}\")\n",
    "# # print(f\"Label Window: {_get_years_range(-3-0, -0)}\")\n",
    "\n",
    "# input_window_size = 5\n",
    "# output_window_size = 3\n",
    "# offset_to_current_year = 3\n",
    "\n",
    "# print(f\"Training Window: {_get_years_range(-input_window_size-output_window_size-offset_to_current_year, -output_window_size-offset_to_current_year)}\")\n",
    "# print(f\"Label Window: {_get_years_range(-output_window_size-offset_to_current_year, -offset_to_current_year)}\")\n",
    "\n",
    "# offset_to_current_year = 0\n",
    "\n",
    "# print(f\"Testing Window: {_get_years_range(-input_window_size-output_window_size-offset_to_current_year, -output_window_size-offset_to_current_year)}\")\n",
    "# print(f\"Label Window: {_get_years_range(-output_window_size-offset_to_current_year, -offset_to_current_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "549adfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NovelSeriesDataset(Dataset):\n",
    "#     def __init__(self, data: np.ndarray, c_inx_arr: np.ndarray, input_window_size: int = 5):\n",
    "#         \"\"\"\n",
    "#         Dataset for novel series data.\n",
    "\n",
    "#         Args:\n",
    "#             data (np.ndarray): The input data.\n",
    "#             c_inx_arr (np.ndarray): Array of concept indices.\n",
    "#             input_window_size (int, optional): Size of the input window. Defaults to 5.\n",
    "#         \"\"\"\n",
    "#         self.train_window_data = data[:, -input_window_size:]\n",
    "#         self.c_inx_arr = c_inx_arr\n",
    "#         self.input_window_size = input_window_size\n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         return 64 * 2000\n",
    "\n",
    "#     def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "#         while True:\n",
    "#             sampled_pair = np.random.choice(self.train_window_data.shape[0], size=2)\n",
    "#             if self.c_inx_arr[sampled_pair[1]] not in word_co_occurrences[self.c_inx_arr[sampled_pair[0]]]:\n",
    "#                 break\n",
    "#         inx_0 = np.where(self.c_inx_arr == self.c_inx_arr[sampled_pair[0]])[0]\n",
    "#         inx_1 = np.where(self.c_inx_arr == self.c_inx_arr[sampled_pair[1]])[0]\n",
    "#         enc_0 = self.train_window_data[inx_0][0]\n",
    "#         enc_1 = self.train_window_data[inx_1][0]\n",
    "#         enc_01 = np.concatenate((enc_0, enc_1), axis=-1)\n",
    "#         return torch.from_numpy(enc_01), torch.from_numpy(np.array([inx_0, inx_1])), inx_0, inx_1\n",
    "\n",
    "#     def _check_indexing(self):\n",
    "#         print(f\"Training Window: {np.unique(saved_year_arr)[-self.input_window_size:]}\")\n",
    "\n",
    "# novel_dataset = NovelSeriesDataset(data=encoding_data, c_inx_arr=c_inx_arr, input_window_size = seq_length)\n",
    "# novel_dataset._check_indexing()\n",
    "# novel_dataloader = DataLoader(novel_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57658937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n",
    "\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, raw_size, drop=.25):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.raw = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Dropout(drop), nn.Linear(raw_size, 128), nn.PReLU(), nn.BatchNorm1d(128),\n",
    "            nn.Dropout(drop), nn.Linear(128, 64), nn.PReLU(), nn.BatchNorm1d(64),\n",
    "            nn.Dropout(drop), nn.Linear( 64, 64), nn.PReLU(), nn.BatchNorm1d(64))\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(64, 32), nn.ReLU(inplace=True), nn.Linear(32, 1), nn.Sigmoid())\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        self.init_weights(nn.init.kaiming_normal_)\n",
    "        \n",
    "    def init_weights(self, init_fn):\n",
    "        def init(m): \n",
    "            for child in m.children():\n",
    "                if isinstance(child, nn.Conv1d):\n",
    "                    init_fn(child.weights)\n",
    "        init(self)\n",
    "        \n",
    "    def forward(self, t_raw):\n",
    "        raw_out = self.raw(t_raw)\n",
    "        out = self.output(raw_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6697f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and validation functions\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # for data, labels, _ in train_loader:\n",
    "    for data, labels, _, _ in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data.float())\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels, _, _ in val_loader:\n",
    "            \n",
    "            outputs = model(data.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "# Training loop with early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, patience=7, file_name='saved_files/best_mlp_model.pth'):\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, val_accuracy = validate_one_epoch(model, val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        logging.info(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                     f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "                     f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "            torch.save(model.state_dict(), file_name)\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                logging.info(\"Early stopping triggered\")\n",
    "                logging.info(\"Best model saved with {best_val_loss:.2f} accuracy\")\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c3d7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(model, dataloader, save=False):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels,_ ,_ in dataloader:\n",
    "            outputs = model(data.float(), )\n",
    "            probs = outputs.cpu().numpy()\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    all_probs = np.array(all_probs).flatten()\n",
    "\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    if save:\n",
    "        np.save(\"fpr_method.npy\", fpr)\n",
    "        np.save(\"tpr_method.npy\", tpr)\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "\n",
    "\n",
    "def plot_roc(model, dataloader):\n",
    "    \n",
    "    fpr, tpr, roc_auc = compute_auc(model, dataloader)\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(3.5, 3))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "# model_mlp.load_state_dict(torch.load('saved_files/best_mlp_model.pth'))\n",
    "# plot_roc(model_mlp, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b20374d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 13:40:35,991 - INFO - Epoch [1/50], Train Loss: 0.4953, Train Accuracy: 77.10%, Val Loss: 0.4696, Val Accuracy: 78.35%\n",
      "2024-08-02 13:40:46,737 - INFO - Epoch [2/50], Train Loss: 0.4787, Train Accuracy: 78.11%, Val Loss: 0.4620, Val Accuracy: 78.83%\n",
      "2024-08-02 13:40:57,301 - INFO - Epoch [3/50], Train Loss: 0.4718, Train Accuracy: 78.37%, Val Loss: 0.4557, Val Accuracy: 79.55%\n",
      "2024-08-02 13:41:07,447 - INFO - Epoch [4/50], Train Loss: 0.4676, Train Accuracy: 78.52%, Val Loss: 0.4562, Val Accuracy: 79.19%\n",
      "2024-08-02 13:41:17,657 - INFO - Epoch [5/50], Train Loss: 0.4634, Train Accuracy: 78.79%, Val Loss: 0.4507, Val Accuracy: 79.66%\n",
      "2024-08-02 13:41:27,476 - INFO - Epoch [6/50], Train Loss: 0.4596, Train Accuracy: 79.00%, Val Loss: 0.4467, Val Accuracy: 79.68%\n",
      "2024-08-02 13:41:37,644 - INFO - Epoch [7/50], Train Loss: 0.4567, Train Accuracy: 79.21%, Val Loss: 0.4430, Val Accuracy: 79.99%\n",
      "2024-08-02 13:41:47,372 - INFO - Epoch [8/50], Train Loss: 0.4540, Train Accuracy: 79.35%, Val Loss: 0.4448, Val Accuracy: 79.88%\n",
      "2024-08-02 13:41:57,150 - INFO - Epoch [9/50], Train Loss: 0.4521, Train Accuracy: 79.46%, Val Loss: 0.4423, Val Accuracy: 80.05%\n",
      "2024-08-02 13:42:07,647 - INFO - Epoch [10/50], Train Loss: 0.4516, Train Accuracy: 79.52%, Val Loss: 0.4423, Val Accuracy: 80.00%\n",
      "2024-08-02 13:42:17,954 - INFO - Epoch [11/50], Train Loss: 0.4505, Train Accuracy: 79.53%, Val Loss: 0.4409, Val Accuracy: 80.15%\n",
      "2024-08-02 13:42:27,999 - INFO - Epoch [12/50], Train Loss: 0.4508, Train Accuracy: 79.52%, Val Loss: 0.4419, Val Accuracy: 80.09%\n",
      "2024-08-02 13:42:38,056 - INFO - Epoch [13/50], Train Loss: 0.4511, Train Accuracy: 79.49%, Val Loss: 0.4441, Val Accuracy: 79.97%\n",
      "2024-08-02 13:42:48,312 - INFO - Epoch [14/50], Train Loss: 0.4519, Train Accuracy: 79.43%, Val Loss: 0.4407, Val Accuracy: 80.07%\n",
      "2024-08-02 13:42:58,541 - INFO - Epoch [15/50], Train Loss: 0.4531, Train Accuracy: 79.40%, Val Loss: 0.4407, Val Accuracy: 80.04%\n",
      "2024-08-02 13:43:09,095 - INFO - Epoch [16/50], Train Loss: 0.4543, Train Accuracy: 79.34%, Val Loss: 0.4523, Val Accuracy: 79.62%\n",
      "2024-08-02 13:43:18,858 - INFO - Epoch [17/50], Train Loss: 0.4557, Train Accuracy: 79.24%, Val Loss: 0.4472, Val Accuracy: 79.83%\n",
      "2024-08-02 13:43:29,237 - INFO - Epoch [18/50], Train Loss: 0.4571, Train Accuracy: 79.16%, Val Loss: 0.4462, Val Accuracy: 79.63%\n",
      "2024-08-02 13:43:39,790 - INFO - Epoch [19/50], Train Loss: 0.4572, Train Accuracy: 79.17%, Val Loss: 0.4431, Val Accuracy: 79.81%\n",
      "2024-08-02 13:43:50,806 - INFO - Epoch [20/50], Train Loss: 0.4576, Train Accuracy: 79.16%, Val Loss: 0.4420, Val Accuracy: 80.03%\n",
      "2024-08-02 13:44:01,789 - INFO - Epoch [21/50], Train Loss: 0.4566, Train Accuracy: 79.20%, Val Loss: 0.4445, Val Accuracy: 79.96%\n",
      "2024-08-02 13:44:11,856 - INFO - Epoch [22/50], Train Loss: 0.4551, Train Accuracy: 79.33%, Val Loss: 0.4429, Val Accuracy: 79.93%\n",
      "2024-08-02 13:44:11,856 - INFO - Early stopping triggered\n",
      "2024-08-02 13:44:11,857 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 10%|█         | 1/10 [04:58<44:48, 298.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 13:45:38,870 - INFO - Epoch [1/50], Train Loss: 0.4941, Train Accuracy: 77.15%, Val Loss: 0.4710, Val Accuracy: 78.27%\n",
      "2024-08-02 13:45:49,910 - INFO - Epoch [2/50], Train Loss: 0.4760, Train Accuracy: 78.16%, Val Loss: 0.4657, Val Accuracy: 78.70%\n",
      "2024-08-02 13:46:00,792 - INFO - Epoch [3/50], Train Loss: 0.4680, Train Accuracy: 78.65%, Val Loss: 0.4561, Val Accuracy: 79.20%\n",
      "2024-08-02 13:46:12,230 - INFO - Epoch [4/50], Train Loss: 0.4630, Train Accuracy: 78.84%, Val Loss: 0.4544, Val Accuracy: 79.28%\n",
      "2024-08-02 13:46:23,317 - INFO - Epoch [5/50], Train Loss: 0.4585, Train Accuracy: 79.09%, Val Loss: 0.4491, Val Accuracy: 79.61%\n",
      "2024-08-02 13:46:35,744 - INFO - Epoch [6/50], Train Loss: 0.4538, Train Accuracy: 79.38%, Val Loss: 0.4495, Val Accuracy: 79.54%\n",
      "2024-08-02 13:46:46,078 - INFO - Epoch [7/50], Train Loss: 0.4504, Train Accuracy: 79.49%, Val Loss: 0.4506, Val Accuracy: 79.46%\n",
      "2024-08-02 13:46:57,160 - INFO - Epoch [8/50], Train Loss: 0.4467, Train Accuracy: 79.73%, Val Loss: 0.4450, Val Accuracy: 79.66%\n",
      "2024-08-02 13:47:07,669 - INFO - Epoch [9/50], Train Loss: 0.4437, Train Accuracy: 79.85%, Val Loss: 0.4427, Val Accuracy: 79.83%\n",
      "2024-08-02 13:47:18,420 - INFO - Epoch [10/50], Train Loss: 0.4429, Train Accuracy: 79.93%, Val Loss: 0.4401, Val Accuracy: 80.05%\n",
      "2024-08-02 13:47:28,123 - INFO - Epoch [11/50], Train Loss: 0.4427, Train Accuracy: 79.92%, Val Loss: 0.4415, Val Accuracy: 79.94%\n",
      "2024-08-02 13:47:39,424 - INFO - Epoch [12/50], Train Loss: 0.4427, Train Accuracy: 79.88%, Val Loss: 0.4410, Val Accuracy: 79.94%\n",
      "2024-08-02 13:47:49,396 - INFO - Epoch [13/50], Train Loss: 0.4436, Train Accuracy: 79.79%, Val Loss: 0.4424, Val Accuracy: 79.86%\n",
      "2024-08-02 13:47:59,858 - INFO - Epoch [14/50], Train Loss: 0.4444, Train Accuracy: 79.71%, Val Loss: 0.4417, Val Accuracy: 79.98%\n",
      "2024-08-02 13:48:09,546 - INFO - Epoch [15/50], Train Loss: 0.4455, Train Accuracy: 79.73%, Val Loss: 0.4412, Val Accuracy: 79.91%\n",
      "2024-08-02 13:48:19,348 - INFO - Epoch [16/50], Train Loss: 0.4472, Train Accuracy: 79.68%, Val Loss: 0.4430, Val Accuracy: 79.85%\n",
      "2024-08-02 13:48:29,679 - INFO - Epoch [17/50], Train Loss: 0.4488, Train Accuracy: 79.55%, Val Loss: 0.4473, Val Accuracy: 79.79%\n",
      "2024-08-02 13:48:29,680 - INFO - Early stopping triggered\n",
      "2024-08-02 13:48:29,680 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 20%|██        | 2/10 [09:16<36:38, 274.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 13:49:52,085 - INFO - Epoch [1/50], Train Loss: 0.4929, Train Accuracy: 77.23%, Val Loss: 0.4694, Val Accuracy: 78.38%\n",
      "2024-08-02 13:50:03,425 - INFO - Epoch [2/50], Train Loss: 0.4722, Train Accuracy: 78.42%, Val Loss: 0.4581, Val Accuracy: 78.92%\n",
      "2024-08-02 13:50:13,905 - INFO - Epoch [3/50], Train Loss: 0.4638, Train Accuracy: 78.91%, Val Loss: 0.4534, Val Accuracy: 79.12%\n",
      "2024-08-02 13:50:24,466 - INFO - Epoch [4/50], Train Loss: 0.4577, Train Accuracy: 79.25%, Val Loss: 0.4483, Val Accuracy: 79.62%\n",
      "2024-08-02 13:50:36,369 - INFO - Epoch [5/50], Train Loss: 0.4525, Train Accuracy: 79.44%, Val Loss: 0.4472, Val Accuracy: 79.84%\n",
      "2024-08-02 13:50:48,575 - INFO - Epoch [6/50], Train Loss: 0.4481, Train Accuracy: 79.66%, Val Loss: 0.4412, Val Accuracy: 80.08%\n",
      "2024-08-02 13:51:00,584 - INFO - Epoch [7/50], Train Loss: 0.4437, Train Accuracy: 79.92%, Val Loss: 0.4425, Val Accuracy: 80.11%\n",
      "2024-08-02 13:51:14,585 - INFO - Epoch [8/50], Train Loss: 0.4401, Train Accuracy: 80.06%, Val Loss: 0.4397, Val Accuracy: 80.13%\n",
      "2024-08-02 13:51:28,611 - INFO - Epoch [9/50], Train Loss: 0.4374, Train Accuracy: 80.22%, Val Loss: 0.4368, Val Accuracy: 80.25%\n",
      "2024-08-02 13:51:42,574 - INFO - Epoch [10/50], Train Loss: 0.4361, Train Accuracy: 80.30%, Val Loss: 0.4404, Val Accuracy: 80.10%\n",
      "2024-08-02 13:51:56,044 - INFO - Epoch [11/50], Train Loss: 0.4351, Train Accuracy: 80.36%, Val Loss: 0.4380, Val Accuracy: 80.18%\n",
      "2024-08-02 13:52:10,494 - INFO - Epoch [12/50], Train Loss: 0.4359, Train Accuracy: 80.32%, Val Loss: 0.4374, Val Accuracy: 80.23%\n",
      "2024-08-02 13:52:23,199 - INFO - Epoch [13/50], Train Loss: 0.4365, Train Accuracy: 80.32%, Val Loss: 0.4359, Val Accuracy: 80.34%\n",
      "2024-08-02 13:52:35,439 - INFO - Epoch [14/50], Train Loss: 0.4369, Train Accuracy: 80.25%, Val Loss: 0.4368, Val Accuracy: 80.40%\n",
      "2024-08-02 13:52:47,750 - INFO - Epoch [15/50], Train Loss: 0.4389, Train Accuracy: 80.07%, Val Loss: 0.4371, Val Accuracy: 80.38%\n",
      "2024-08-02 13:52:59,824 - INFO - Epoch [16/50], Train Loss: 0.4402, Train Accuracy: 80.04%, Val Loss: 0.4392, Val Accuracy: 80.24%\n",
      "2024-08-02 13:53:11,880 - INFO - Epoch [17/50], Train Loss: 0.4431, Train Accuracy: 79.94%, Val Loss: 0.4436, Val Accuracy: 80.04%\n",
      "2024-08-02 13:53:24,845 - INFO - Epoch [18/50], Train Loss: 0.4433, Train Accuracy: 79.88%, Val Loss: 0.4413, Val Accuracy: 79.83%\n",
      "2024-08-02 13:53:38,677 - INFO - Epoch [19/50], Train Loss: 0.4442, Train Accuracy: 79.84%, Val Loss: 0.4408, Val Accuracy: 79.95%\n",
      "2024-08-02 13:53:52,195 - INFO - Epoch [20/50], Train Loss: 0.4437, Train Accuracy: 79.92%, Val Loss: 0.4416, Val Accuracy: 79.93%\n",
      "2024-08-02 13:53:52,195 - INFO - Early stopping triggered\n",
      "2024-08-02 13:53:52,196 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 30%|███       | 3/10 [14:40<34:40, 297.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2014 2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2017 2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 13:55:22,766 - INFO - Epoch [1/50], Train Loss: 0.4928, Train Accuracy: 77.26%, Val Loss: 0.4716, Val Accuracy: 78.47%\n",
      "2024-08-02 13:55:37,032 - INFO - Epoch [2/50], Train Loss: 0.4732, Train Accuracy: 78.39%, Val Loss: 0.4701, Val Accuracy: 78.59%\n",
      "2024-08-02 13:55:50,571 - INFO - Epoch [3/50], Train Loss: 0.4643, Train Accuracy: 78.89%, Val Loss: 0.4587, Val Accuracy: 79.13%\n",
      "2024-08-02 13:56:03,719 - INFO - Epoch [4/50], Train Loss: 0.4582, Train Accuracy: 79.14%, Val Loss: 0.4482, Val Accuracy: 79.60%\n",
      "2024-08-02 13:56:17,249 - INFO - Epoch [5/50], Train Loss: 0.4525, Train Accuracy: 79.46%, Val Loss: 0.4475, Val Accuracy: 79.81%\n",
      "2024-08-02 13:56:30,452 - INFO - Epoch [6/50], Train Loss: 0.4476, Train Accuracy: 79.76%, Val Loss: 0.4428, Val Accuracy: 79.89%\n",
      "2024-08-02 13:56:42,965 - INFO - Epoch [7/50], Train Loss: 0.4422, Train Accuracy: 79.93%, Val Loss: 0.4416, Val Accuracy: 79.95%\n",
      "2024-08-02 13:56:55,298 - INFO - Epoch [8/50], Train Loss: 0.4386, Train Accuracy: 80.13%, Val Loss: 0.4387, Val Accuracy: 80.10%\n",
      "2024-08-02 13:57:08,705 - INFO - Epoch [9/50], Train Loss: 0.4358, Train Accuracy: 80.21%, Val Loss: 0.4385, Val Accuracy: 80.17%\n",
      "2024-08-02 13:57:21,741 - INFO - Epoch [10/50], Train Loss: 0.4341, Train Accuracy: 80.36%, Val Loss: 0.4403, Val Accuracy: 80.01%\n",
      "2024-08-02 13:57:35,376 - INFO - Epoch [11/50], Train Loss: 0.4340, Train Accuracy: 80.35%, Val Loss: 0.4384, Val Accuracy: 80.13%\n",
      "2024-08-02 13:57:49,495 - INFO - Epoch [12/50], Train Loss: 0.4339, Train Accuracy: 80.38%, Val Loss: 0.4389, Val Accuracy: 80.12%\n",
      "2024-08-02 13:58:03,122 - INFO - Epoch [13/50], Train Loss: 0.4348, Train Accuracy: 80.35%, Val Loss: 0.4374, Val Accuracy: 80.21%\n",
      "2024-08-02 13:58:16,838 - INFO - Epoch [14/50], Train Loss: 0.4357, Train Accuracy: 80.28%, Val Loss: 0.4365, Val Accuracy: 80.22%\n",
      "2024-08-02 13:58:30,295 - INFO - Epoch [15/50], Train Loss: 0.4368, Train Accuracy: 80.26%, Val Loss: 0.4391, Val Accuracy: 80.12%\n",
      "2024-08-02 13:58:43,238 - INFO - Epoch [16/50], Train Loss: 0.4385, Train Accuracy: 80.19%, Val Loss: 0.4380, Val Accuracy: 80.08%\n",
      "2024-08-02 13:58:55,330 - INFO - Epoch [17/50], Train Loss: 0.4406, Train Accuracy: 80.06%, Val Loss: 0.4407, Val Accuracy: 79.88%\n",
      "2024-08-02 13:59:07,536 - INFO - Epoch [18/50], Train Loss: 0.4424, Train Accuracy: 79.92%, Val Loss: 0.4400, Val Accuracy: 79.96%\n",
      "2024-08-02 13:59:19,073 - INFO - Epoch [19/50], Train Loss: 0.4428, Train Accuracy: 79.90%, Val Loss: 0.4449, Val Accuracy: 79.95%\n",
      "2024-08-02 13:59:30,892 - INFO - Epoch [20/50], Train Loss: 0.4433, Train Accuracy: 79.86%, Val Loss: 0.4394, Val Accuracy: 80.02%\n",
      "2024-08-02 13:59:43,257 - INFO - Epoch [21/50], Train Loss: 0.4414, Train Accuracy: 79.97%, Val Loss: 0.4370, Val Accuracy: 80.37%\n",
      "2024-08-02 13:59:43,257 - INFO - Early stopping triggered\n",
      "2024-08-02 13:59:43,258 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 40%|████      | 4/10 [20:30<31:48, 318.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2013 2014 2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2016 2017 2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 14:01:08,692 - INFO - Epoch [1/50], Train Loss: 0.4927, Train Accuracy: 77.31%, Val Loss: 0.4685, Val Accuracy: 78.61%\n",
      "2024-08-02 14:01:21,377 - INFO - Epoch [2/50], Train Loss: 0.4708, Train Accuracy: 78.55%, Val Loss: 0.4553, Val Accuracy: 79.18%\n",
      "2024-08-02 14:01:33,511 - INFO - Epoch [3/50], Train Loss: 0.4607, Train Accuracy: 79.11%, Val Loss: 0.4519, Val Accuracy: 79.33%\n",
      "2024-08-02 14:01:47,319 - INFO - Epoch [4/50], Train Loss: 0.4540, Train Accuracy: 79.42%, Val Loss: 0.4515, Val Accuracy: 79.25%\n",
      "2024-08-02 14:01:59,818 - INFO - Epoch [5/50], Train Loss: 0.4478, Train Accuracy: 79.74%, Val Loss: 0.4420, Val Accuracy: 79.85%\n",
      "2024-08-02 14:02:13,482 - INFO - Epoch [6/50], Train Loss: 0.4418, Train Accuracy: 80.04%, Val Loss: 0.4390, Val Accuracy: 80.09%\n",
      "2024-08-02 14:02:29,317 - INFO - Epoch [7/50], Train Loss: 0.4370, Train Accuracy: 80.25%, Val Loss: 0.4376, Val Accuracy: 80.13%\n",
      "2024-08-02 14:02:43,766 - INFO - Epoch [8/50], Train Loss: 0.4331, Train Accuracy: 80.46%, Val Loss: 0.4367, Val Accuracy: 80.15%\n",
      "2024-08-02 14:02:57,862 - INFO - Epoch [9/50], Train Loss: 0.4305, Train Accuracy: 80.53%, Val Loss: 0.4343, Val Accuracy: 80.33%\n",
      "2024-08-02 14:03:12,210 - INFO - Epoch [10/50], Train Loss: 0.4282, Train Accuracy: 80.68%, Val Loss: 0.4341, Val Accuracy: 80.37%\n",
      "2024-08-02 14:03:26,978 - INFO - Epoch [11/50], Train Loss: 0.4270, Train Accuracy: 80.79%, Val Loss: 0.4335, Val Accuracy: 80.35%\n",
      "2024-08-02 14:03:41,123 - INFO - Epoch [12/50], Train Loss: 0.4278, Train Accuracy: 80.71%, Val Loss: 0.4342, Val Accuracy: 80.39%\n",
      "2024-08-02 14:03:55,394 - INFO - Epoch [13/50], Train Loss: 0.4286, Train Accuracy: 80.65%, Val Loss: 0.4358, Val Accuracy: 80.27%\n",
      "2024-08-02 14:04:09,533 - INFO - Epoch [14/50], Train Loss: 0.4303, Train Accuracy: 80.56%, Val Loss: 0.4353, Val Accuracy: 80.24%\n",
      "2024-08-02 14:04:23,698 - INFO - Epoch [15/50], Train Loss: 0.4312, Train Accuracy: 80.47%, Val Loss: 0.4343, Val Accuracy: 80.48%\n",
      "2024-08-02 14:04:37,857 - INFO - Epoch [16/50], Train Loss: 0.4337, Train Accuracy: 80.48%, Val Loss: 0.4346, Val Accuracy: 80.36%\n",
      "2024-08-02 14:04:52,227 - INFO - Epoch [17/50], Train Loss: 0.4353, Train Accuracy: 80.31%, Val Loss: 0.4357, Val Accuracy: 80.08%\n",
      "2024-08-02 14:05:07,098 - INFO - Epoch [18/50], Train Loss: 0.4368, Train Accuracy: 80.21%, Val Loss: 0.4358, Val Accuracy: 80.17%\n",
      "2024-08-02 14:05:07,098 - INFO - Early stopping triggered\n",
      "2024-08-02 14:05:07,099 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 50%|█████     | 5/10 [25:56<26:44, 320.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2012 2013 2014 2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2015 2016 2017 2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 14:06:39,768 - INFO - Epoch [1/50], Train Loss: 0.4938, Train Accuracy: 77.17%, Val Loss: 0.4688, Val Accuracy: 78.51%\n",
      "2024-08-02 14:06:56,929 - INFO - Epoch [2/50], Train Loss: 0.4710, Train Accuracy: 78.52%, Val Loss: 0.4591, Val Accuracy: 79.32%\n",
      "2024-08-02 14:07:13,192 - INFO - Epoch [3/50], Train Loss: 0.4607, Train Accuracy: 78.97%, Val Loss: 0.4482, Val Accuracy: 79.67%\n",
      "2024-08-02 14:07:30,394 - INFO - Epoch [4/50], Train Loss: 0.4534, Train Accuracy: 79.50%, Val Loss: 0.4450, Val Accuracy: 79.84%\n",
      "2024-08-02 14:07:47,256 - INFO - Epoch [5/50], Train Loss: 0.4472, Train Accuracy: 79.82%, Val Loss: 0.4427, Val Accuracy: 80.05%\n",
      "2024-08-02 14:08:03,893 - INFO - Epoch [6/50], Train Loss: 0.4425, Train Accuracy: 79.96%, Val Loss: 0.4398, Val Accuracy: 80.21%\n",
      "2024-08-02 14:08:19,312 - INFO - Epoch [7/50], Train Loss: 0.4369, Train Accuracy: 80.28%, Val Loss: 0.4386, Val Accuracy: 80.38%\n",
      "2024-08-02 14:08:32,801 - INFO - Epoch [8/50], Train Loss: 0.4323, Train Accuracy: 80.59%, Val Loss: 0.4358, Val Accuracy: 80.41%\n",
      "2024-08-02 14:08:45,299 - INFO - Epoch [9/50], Train Loss: 0.4284, Train Accuracy: 80.73%, Val Loss: 0.4347, Val Accuracy: 80.50%\n",
      "2024-08-02 14:08:57,967 - INFO - Epoch [10/50], Train Loss: 0.4266, Train Accuracy: 80.83%, Val Loss: 0.4346, Val Accuracy: 80.51%\n",
      "2024-08-02 14:09:11,293 - INFO - Epoch [11/50], Train Loss: 0.4265, Train Accuracy: 80.90%, Val Loss: 0.4329, Val Accuracy: 80.51%\n",
      "2024-08-02 14:09:25,415 - INFO - Epoch [12/50], Train Loss: 0.4269, Train Accuracy: 80.80%, Val Loss: 0.4338, Val Accuracy: 80.54%\n",
      "2024-08-02 14:09:38,910 - INFO - Epoch [13/50], Train Loss: 0.4275, Train Accuracy: 80.79%, Val Loss: 0.4335, Val Accuracy: 80.54%\n",
      "2024-08-02 14:09:53,107 - INFO - Epoch [14/50], Train Loss: 0.4291, Train Accuracy: 80.70%, Val Loss: 0.4329, Val Accuracy: 80.51%\n",
      "2024-08-02 14:10:08,259 - INFO - Epoch [15/50], Train Loss: 0.4304, Train Accuracy: 80.69%, Val Loss: 0.4337, Val Accuracy: 80.50%\n",
      "2024-08-02 14:10:21,851 - INFO - Epoch [16/50], Train Loss: 0.4319, Train Accuracy: 80.54%, Val Loss: 0.4377, Val Accuracy: 80.14%\n",
      "2024-08-02 14:10:35,448 - INFO - Epoch [17/50], Train Loss: 0.4349, Train Accuracy: 80.31%, Val Loss: 0.4347, Val Accuracy: 80.48%\n",
      "2024-08-02 14:10:48,128 - INFO - Epoch [18/50], Train Loss: 0.4363, Train Accuracy: 80.33%, Val Loss: 0.4378, Val Accuracy: 80.31%\n",
      "2024-08-02 14:11:01,143 - INFO - Epoch [19/50], Train Loss: 0.4363, Train Accuracy: 80.20%, Val Loss: 0.4356, Val Accuracy: 80.36%\n",
      "2024-08-02 14:11:13,841 - INFO - Epoch [20/50], Train Loss: 0.4362, Train Accuracy: 80.24%, Val Loss: 0.4361, Val Accuracy: 80.34%\n",
      "2024-08-02 14:11:26,813 - INFO - Epoch [21/50], Train Loss: 0.4358, Train Accuracy: 80.26%, Val Loss: 0.4372, Val Accuracy: 80.22%\n",
      "2024-08-02 14:11:26,813 - INFO - Early stopping triggered\n",
      "2024-08-02 14:11:26,814 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 60%|██████    | 6/10 [32:15<22:41, 340.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2011 2012 2013 2014 2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2014 2015 2016 2017 2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 14:12:53,700 - INFO - Epoch [1/50], Train Loss: 0.4949, Train Accuracy: 77.25%, Val Loss: 0.4622, Val Accuracy: 78.85%\n",
      "2024-08-02 14:13:07,921 - INFO - Epoch [2/50], Train Loss: 0.4712, Train Accuracy: 78.52%, Val Loss: 0.4565, Val Accuracy: 79.35%\n",
      "2024-08-02 14:13:21,890 - INFO - Epoch [3/50], Train Loss: 0.4602, Train Accuracy: 79.06%, Val Loss: 0.4506, Val Accuracy: 79.45%\n",
      "2024-08-02 14:13:36,235 - INFO - Epoch [4/50], Train Loss: 0.4528, Train Accuracy: 79.49%, Val Loss: 0.4447, Val Accuracy: 79.82%\n",
      "2024-08-02 14:13:49,815 - INFO - Epoch [5/50], Train Loss: 0.4457, Train Accuracy: 79.76%, Val Loss: 0.4420, Val Accuracy: 80.03%\n",
      "2024-08-02 14:14:04,079 - INFO - Epoch [6/50], Train Loss: 0.4401, Train Accuracy: 80.12%, Val Loss: 0.4385, Val Accuracy: 80.26%\n",
      "2024-08-02 14:14:18,917 - INFO - Epoch [7/50], Train Loss: 0.4350, Train Accuracy: 80.34%, Val Loss: 0.4363, Val Accuracy: 80.38%\n",
      "2024-08-02 14:14:33,358 - INFO - Epoch [8/50], Train Loss: 0.4301, Train Accuracy: 80.68%, Val Loss: 0.4353, Val Accuracy: 80.36%\n",
      "2024-08-02 14:14:47,529 - INFO - Epoch [9/50], Train Loss: 0.4267, Train Accuracy: 80.83%, Val Loss: 0.4337, Val Accuracy: 80.43%\n",
      "2024-08-02 14:15:01,574 - INFO - Epoch [10/50], Train Loss: 0.4251, Train Accuracy: 80.92%, Val Loss: 0.4326, Val Accuracy: 80.54%\n",
      "2024-08-02 14:15:15,632 - INFO - Epoch [11/50], Train Loss: 0.4241, Train Accuracy: 80.97%, Val Loss: 0.4322, Val Accuracy: 80.52%\n",
      "2024-08-02 14:15:29,248 - INFO - Epoch [12/50], Train Loss: 0.4238, Train Accuracy: 80.92%, Val Loss: 0.4326, Val Accuracy: 80.52%\n",
      "2024-08-02 14:15:42,928 - INFO - Epoch [13/50], Train Loss: 0.4247, Train Accuracy: 80.87%, Val Loss: 0.4378, Val Accuracy: 80.30%\n",
      "2024-08-02 14:15:57,530 - INFO - Epoch [14/50], Train Loss: 0.4269, Train Accuracy: 80.88%, Val Loss: 0.4334, Val Accuracy: 80.50%\n",
      "2024-08-02 14:16:12,105 - INFO - Epoch [15/50], Train Loss: 0.4279, Train Accuracy: 80.75%, Val Loss: 0.4340, Val Accuracy: 80.47%\n",
      "2024-08-02 14:16:26,239 - INFO - Epoch [16/50], Train Loss: 0.4312, Train Accuracy: 80.51%, Val Loss: 0.4339, Val Accuracy: 80.32%\n",
      "2024-08-02 14:16:40,482 - INFO - Epoch [17/50], Train Loss: 0.4332, Train Accuracy: 80.46%, Val Loss: 0.4350, Val Accuracy: 80.33%\n",
      "2024-08-02 14:16:54,824 - INFO - Epoch [18/50], Train Loss: 0.4343, Train Accuracy: 80.43%, Val Loss: 0.4373, Val Accuracy: 80.20%\n",
      "2024-08-02 14:16:54,825 - INFO - Early stopping triggered\n",
      "2024-08-02 14:16:54,825 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 70%|███████   | 7/10 [37:44<16:50, 336.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2010 2011 2012 2013 2014 2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2013 2014 2015 2016 2017 2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 14:18:25,229 - INFO - Epoch [1/50], Train Loss: 0.4954, Train Accuracy: 77.06%, Val Loss: 0.4641, Val Accuracy: 78.69%\n",
      "2024-08-02 14:18:39,846 - INFO - Epoch [2/50], Train Loss: 0.4700, Train Accuracy: 78.49%, Val Loss: 0.4567, Val Accuracy: 79.29%\n",
      "2024-08-02 14:18:54,871 - INFO - Epoch [3/50], Train Loss: 0.4595, Train Accuracy: 79.10%, Val Loss: 0.4479, Val Accuracy: 79.76%\n",
      "2024-08-02 14:19:09,754 - INFO - Epoch [4/50], Train Loss: 0.4517, Train Accuracy: 79.49%, Val Loss: 0.4454, Val Accuracy: 79.88%\n",
      "2024-08-02 14:19:24,405 - INFO - Epoch [5/50], Train Loss: 0.4441, Train Accuracy: 79.95%, Val Loss: 0.4418, Val Accuracy: 80.21%\n",
      "2024-08-02 14:19:39,186 - INFO - Epoch [6/50], Train Loss: 0.4378, Train Accuracy: 80.21%, Val Loss: 0.4374, Val Accuracy: 80.31%\n",
      "2024-08-02 14:19:54,349 - INFO - Epoch [7/50], Train Loss: 0.4327, Train Accuracy: 80.46%, Val Loss: 0.4331, Val Accuracy: 80.48%\n",
      "2024-08-02 14:20:08,722 - INFO - Epoch [8/50], Train Loss: 0.4274, Train Accuracy: 80.69%, Val Loss: 0.4316, Val Accuracy: 80.62%\n",
      "2024-08-02 14:20:23,016 - INFO - Epoch [9/50], Train Loss: 0.4236, Train Accuracy: 80.96%, Val Loss: 0.4307, Val Accuracy: 80.70%\n",
      "2024-08-02 14:20:37,846 - INFO - Epoch [10/50], Train Loss: 0.4217, Train Accuracy: 81.00%, Val Loss: 0.4307, Val Accuracy: 80.61%\n",
      "2024-08-02 14:20:52,621 - INFO - Epoch [11/50], Train Loss: 0.4208, Train Accuracy: 81.09%, Val Loss: 0.4316, Val Accuracy: 80.64%\n",
      "2024-08-02 14:21:07,830 - INFO - Epoch [12/50], Train Loss: 0.4209, Train Accuracy: 81.03%, Val Loss: 0.4301, Val Accuracy: 80.63%\n",
      "2024-08-02 14:21:22,748 - INFO - Epoch [13/50], Train Loss: 0.4223, Train Accuracy: 81.01%, Val Loss: 0.4308, Val Accuracy: 80.65%\n",
      "2024-08-02 14:21:37,935 - INFO - Epoch [14/50], Train Loss: 0.4237, Train Accuracy: 80.92%, Val Loss: 0.4320, Val Accuracy: 80.61%\n",
      "2024-08-02 14:21:53,283 - INFO - Epoch [15/50], Train Loss: 0.4256, Train Accuracy: 80.86%, Val Loss: 0.4312, Val Accuracy: 80.58%\n",
      "2024-08-02 14:22:08,599 - INFO - Epoch [16/50], Train Loss: 0.4282, Train Accuracy: 80.74%, Val Loss: 0.4322, Val Accuracy: 80.59%\n",
      "2024-08-02 14:22:24,339 - INFO - Epoch [17/50], Train Loss: 0.4302, Train Accuracy: 80.54%, Val Loss: 0.4324, Val Accuracy: 80.50%\n",
      "2024-08-02 14:22:39,788 - INFO - Epoch [18/50], Train Loss: 0.4317, Train Accuracy: 80.44%, Val Loss: 0.4344, Val Accuracy: 80.44%\n",
      "2024-08-02 14:22:55,394 - INFO - Epoch [19/50], Train Loss: 0.4323, Train Accuracy: 80.43%, Val Loss: 0.4385, Val Accuracy: 80.39%\n",
      "2024-08-02 14:22:55,394 - INFO - Early stopping triggered\n",
      "2024-08-02 14:22:55,395 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 80%|████████  | 8/10 [43:45<11:29, 344.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2009 2010 2011 2012 2013 2014 2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2012 2013 2014 2015 2016 2017 2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 14:24:27,760 - INFO - Epoch [1/50], Train Loss: 0.4936, Train Accuracy: 77.25%, Val Loss: 0.4695, Val Accuracy: 78.45%\n",
      "2024-08-02 14:24:44,262 - INFO - Epoch [2/50], Train Loss: 0.4700, Train Accuracy: 78.54%, Val Loss: 0.4603, Val Accuracy: 79.11%\n",
      "2024-08-02 14:25:03,823 - INFO - Epoch [3/50], Train Loss: 0.4581, Train Accuracy: 79.29%, Val Loss: 0.4514, Val Accuracy: 79.44%\n",
      "2024-08-02 14:25:25,580 - INFO - Epoch [4/50], Train Loss: 0.4506, Train Accuracy: 79.64%, Val Loss: 0.4462, Val Accuracy: 79.87%\n",
      "2024-08-02 14:25:41,980 - INFO - Epoch [5/50], Train Loss: 0.4431, Train Accuracy: 79.96%, Val Loss: 0.4442, Val Accuracy: 79.98%\n",
      "2024-08-02 14:26:00,116 - INFO - Epoch [6/50], Train Loss: 0.4366, Train Accuracy: 80.29%, Val Loss: 0.4383, Val Accuracy: 80.13%\n",
      "2024-08-02 14:26:19,070 - INFO - Epoch [7/50], Train Loss: 0.4304, Train Accuracy: 80.67%, Val Loss: 0.4357, Val Accuracy: 80.29%\n",
      "2024-08-02 14:26:38,881 - INFO - Epoch [8/50], Train Loss: 0.4264, Train Accuracy: 80.83%, Val Loss: 0.4346, Val Accuracy: 80.34%\n",
      "2024-08-02 14:26:56,847 - INFO - Epoch [9/50], Train Loss: 0.4212, Train Accuracy: 81.07%, Val Loss: 0.4336, Val Accuracy: 80.39%\n",
      "2024-08-02 14:27:12,830 - INFO - Epoch [10/50], Train Loss: 0.4196, Train Accuracy: 81.15%, Val Loss: 0.4327, Val Accuracy: 80.54%\n",
      "2024-08-02 14:27:31,131 - INFO - Epoch [11/50], Train Loss: 0.4191, Train Accuracy: 81.16%, Val Loss: 0.4326, Val Accuracy: 80.48%\n",
      "2024-08-02 14:27:49,941 - INFO - Epoch [12/50], Train Loss: 0.4196, Train Accuracy: 81.17%, Val Loss: 0.4324, Val Accuracy: 80.47%\n",
      "2024-08-02 14:28:08,624 - INFO - Epoch [13/50], Train Loss: 0.4205, Train Accuracy: 81.14%, Val Loss: 0.4322, Val Accuracy: 80.50%\n",
      "2024-08-02 14:28:27,213 - INFO - Epoch [14/50], Train Loss: 0.4213, Train Accuracy: 81.00%, Val Loss: 0.4325, Val Accuracy: 80.46%\n",
      "2024-08-02 14:28:46,126 - INFO - Epoch [15/50], Train Loss: 0.4240, Train Accuracy: 80.88%, Val Loss: 0.4325, Val Accuracy: 80.44%\n",
      "2024-08-02 14:29:05,107 - INFO - Epoch [16/50], Train Loss: 0.4265, Train Accuracy: 80.73%, Val Loss: 0.4363, Val Accuracy: 80.20%\n",
      "2024-08-02 14:29:23,678 - INFO - Epoch [17/50], Train Loss: 0.4284, Train Accuracy: 80.62%, Val Loss: 0.4353, Val Accuracy: 80.29%\n",
      "2024-08-02 14:29:42,174 - INFO - Epoch [18/50], Train Loss: 0.4303, Train Accuracy: 80.58%, Val Loss: 0.4365, Val Accuracy: 80.39%\n",
      "2024-08-02 14:30:02,432 - INFO - Epoch [19/50], Train Loss: 0.4311, Train Accuracy: 80.47%, Val Loss: 0.4384, Val Accuracy: 80.35%\n",
      "2024-08-02 14:30:22,217 - INFO - Epoch [20/50], Train Loss: 0.4305, Train Accuracy: 80.56%, Val Loss: 0.4379, Val Accuracy: 80.28%\n",
      "2024-08-02 14:30:22,218 - INFO - Early stopping triggered\n",
      "2024-08-02 14:30:22,218 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      " 90%|█████████ | 9/10 [51:14<06:17, 377.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Window: [2008 2009 2010 2011 2012 2013 2014 2015 2016 2017]\n",
      "Label Window: [2018 2019 2020]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2018 2019 2020]\n",
      "Negative: Expect to be 0:  0\n",
      "Training Window: [2011 2012 2013 2014 2015 2016 2017 2018 2019 2020]\n",
      "Label Window: [2021 2022 2023]\n",
      "Finished Positives\n",
      "Finished Negatives\n",
      "Positive: Expect to be years:  [2021 2022 2023]\n",
      "Negative: Expect to be 0:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 14:31:57,009 - INFO - Epoch [1/50], Train Loss: 0.4945, Train Accuracy: 77.10%, Val Loss: 0.4702, Val Accuracy: 78.41%\n",
      "2024-08-02 14:32:12,573 - INFO - Epoch [2/50], Train Loss: 0.4693, Train Accuracy: 78.61%, Val Loss: 0.4579, Val Accuracy: 79.35%\n",
      "2024-08-02 14:32:28,236 - INFO - Epoch [3/50], Train Loss: 0.4581, Train Accuracy: 79.16%, Val Loss: 0.4476, Val Accuracy: 79.70%\n",
      "2024-08-02 14:32:43,701 - INFO - Epoch [4/50], Train Loss: 0.4499, Train Accuracy: 79.61%, Val Loss: 0.4455, Val Accuracy: 80.05%\n",
      "2024-08-02 14:32:59,415 - INFO - Epoch [5/50], Train Loss: 0.4417, Train Accuracy: 80.05%, Val Loss: 0.4385, Val Accuracy: 80.26%\n",
      "2024-08-02 14:33:15,117 - INFO - Epoch [6/50], Train Loss: 0.4346, Train Accuracy: 80.41%, Val Loss: 0.4346, Val Accuracy: 80.44%\n",
      "2024-08-02 14:33:31,012 - INFO - Epoch [7/50], Train Loss: 0.4288, Train Accuracy: 80.72%, Val Loss: 0.4341, Val Accuracy: 80.61%\n",
      "2024-08-02 14:33:46,604 - INFO - Epoch [8/50], Train Loss: 0.4239, Train Accuracy: 81.05%, Val Loss: 0.4316, Val Accuracy: 80.72%\n",
      "2024-08-02 14:34:02,280 - INFO - Epoch [9/50], Train Loss: 0.4198, Train Accuracy: 81.14%, Val Loss: 0.4303, Val Accuracy: 80.77%\n",
      "2024-08-02 14:34:18,167 - INFO - Epoch [10/50], Train Loss: 0.4171, Train Accuracy: 81.31%, Val Loss: 0.4304, Val Accuracy: 80.81%\n",
      "2024-08-02 14:34:33,605 - INFO - Epoch [11/50], Train Loss: 0.4157, Train Accuracy: 81.39%, Val Loss: 0.4306, Val Accuracy: 80.77%\n",
      "2024-08-02 14:34:49,032 - INFO - Epoch [12/50], Train Loss: 0.4164, Train Accuracy: 81.36%, Val Loss: 0.4301, Val Accuracy: 80.83%\n",
      "2024-08-02 14:35:04,689 - INFO - Epoch [13/50], Train Loss: 0.4166, Train Accuracy: 81.27%, Val Loss: 0.4302, Val Accuracy: 80.85%\n",
      "2024-08-02 14:35:20,445 - INFO - Epoch [14/50], Train Loss: 0.4194, Train Accuracy: 81.15%, Val Loss: 0.4303, Val Accuracy: 80.80%\n",
      "2024-08-02 14:35:38,368 - INFO - Epoch [15/50], Train Loss: 0.4215, Train Accuracy: 81.04%, Val Loss: 0.4308, Val Accuracy: 80.72%\n",
      "2024-08-02 14:35:57,400 - INFO - Epoch [16/50], Train Loss: 0.4249, Train Accuracy: 80.94%, Val Loss: 0.4334, Val Accuracy: 80.72%\n",
      "2024-08-02 14:36:16,629 - INFO - Epoch [17/50], Train Loss: 0.4259, Train Accuracy: 80.79%, Val Loss: 0.4314, Val Accuracy: 80.64%\n",
      "2024-08-02 14:36:36,277 - INFO - Epoch [18/50], Train Loss: 0.4286, Train Accuracy: 80.64%, Val Loss: 0.4331, Val Accuracy: 80.58%\n",
      "2024-08-02 14:36:55,490 - INFO - Epoch [19/50], Train Loss: 0.4292, Train Accuracy: 80.60%, Val Loss: 0.4335, Val Accuracy: 80.45%\n",
      "2024-08-02 14:36:55,491 - INFO - Early stopping triggered\n",
      "2024-08-02 14:36:55,492 - INFO - Best model saved with {best_val_loss:.2f} accuracy\n",
      "100%|██████████| 10/10 [57:49<00:00, 346.94s/it]\n"
     ]
    }
   ],
   "source": [
    "auc_arr = []\n",
    "for seq_length in tqdm([1,2,3,4,5,6,7,8,9,10]):\n",
    "    out_length = 3\n",
    "    batch_size = 128\n",
    "\n",
    "    train_pos_inx_pair_arr_5_3_3, train_neg_inx_pair_arr_5_3_3 = create_dataset_indexing(data=encoding_data, word_co_occurrences=word_co_occurrences, year_arr = np.unique(saved_year_arr), \n",
    "                                c_inx_arr=c_inx_arr, input_window_size = seq_length, output_window_size = out_length, offset_to_current_year = 3, print_test=True)\n",
    "\n",
    "    train_pos_inx_pair_arr_5_3_0, train_neg_inx_pair_arr_5_3_0 = create_dataset_indexing(data=encoding_data, word_co_occurrences=word_co_occurrences, year_arr = np.unique(saved_year_arr), \n",
    "                                c_inx_arr=c_inx_arr, input_window_size = seq_length, output_window_size = out_length, offset_to_current_year = 0, print_test=True)\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset, val_dataset = create_train_val_datasets(\n",
    "        train_window_data=encoding_data, pos_inx_pair_arr=train_pos_inx_pair_arr_5_3_3, neg_inx_pair_arr=train_neg_inx_pair_arr_5_3_3, \n",
    "        input_window_size=seq_length, output_window_size=out_length, offset_to_current_year = 3, test_size=0.2)\n",
    "\n",
    "    test_dataset = create_test_datasets(\n",
    "        train_window_data=encoding_data, pos_inx_pair_arr=train_pos_inx_pair_arr_5_3_0, neg_inx_pair_arr=train_neg_inx_pair_arr_5_3_0, \n",
    "        input_window_size=seq_length, output_window_size=out_length, offset_to_current_year = 0)\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize logging\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    # Example usage\n",
    "    input_dim = train_dataset.train_window_data.shape[1] * train_dataset.train_window_data.shape[2] * 2  \n",
    "    model_mlp = MLP(input_dim)\n",
    "\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model_mlp.parameters(), lr=0.005)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    train_model(model_mlp, train_dataloader, val_dataloader, criterion, optimizer, scheduler, file_name=f\"saved_files/best_seq_{seq_length}_model.pth\")\n",
    "    model_mlp.load_state_dict(torch.load(f\"saved_files/best_seq_{seq_length}_model.pth\"))\n",
    "    auc_arr.append(compute_auc(model_mlp, test_dataloader)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e5fbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x744086ceb2b0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(auc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc00e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_top_n(model, dataloader):\n",
    "#     model.eval()\n",
    "#     all_precision = []\n",
    "#     all_rand_precision = []\n",
    "#     with torch.no_grad():\n",
    "#         for data, labels,_ ,_ in dataloader:\n",
    "#             outputs = model(data.float(), )\n",
    "\n",
    "#             predicted = (outputs > 0.5).float()\n",
    "#             precision_ = precision_score(labels,predicted)\n",
    "            \n",
    "#             all_precision.extend([precision_])\n",
    "#             precision_rand = precision_score(labels,np.random.randint(0,2,len(predicted)))\n",
    "#             all_rand_precision.extend([precision_rand])\n",
    "\n",
    "#     all_precision = np.array(all_precision).flatten()\n",
    "#     all_rand_precision = np.array(all_rand_precision).flatten()\n",
    "\n",
    "#     plt.figure(figsize=(3.5, 3))\n",
    "#     plt.plot(np.sort(all_precision)[:500][::-1], color='darkorange', lw=2, label=\"Model Selection\")\n",
    "#     plt.plot([0, 500], [np.mean(all_rand_precision), np.mean(all_rand_precision)], color='navy', lw=2, linestyle='--',label=\"Random Selection\")\n",
    "#     # plt.xlim([0.0, 1.0])\n",
    "#     # plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('Index of Research Suggestion')\n",
    "#     plt.ylabel('Precision')\n",
    "#     plt.title('Top-N Precision')\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "#     plt.show()\n",
    "\n",
    "# plot_top_n(model_mlp, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52478e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_decision_boundary(model, dataloader, steps=100, steps_plot=1000, color_map='Paired'):\n",
    "#     color_map = plt.get_cmap(color_map)\n",
    "#     model.eval()\n",
    "\n",
    "#     all_data = []\n",
    "#     all_labels = []\n",
    "    \n",
    "#     # Collect all the data and labels from the dataloader\n",
    "#     with torch.no_grad():\n",
    "#         for cnt, (data, labels, _, _) in enumerate(dataloader):\n",
    "#             all_data.append(data)\n",
    "#             all_labels.append(labels)\n",
    "#             if cnt == steps:\n",
    "#                 break\n",
    "    \n",
    "#     all_data = torch.cat(all_data)  # Shape: (total_samples, time_steps, features)\n",
    "#     all_labels = torch.cat(all_labels)\n",
    "    \n",
    "#     # Use the final time step for PCA reduction\n",
    "#     final_time_step_data = all_data[:, -1, :]  # Shape: (total_samples, features)\n",
    "    \n",
    "#     # Apply PCA to reduce dimensionality to 2D\n",
    "#     pca = PCA(n_components=2)\n",
    "#     reduced_data = pca.fit_transform(final_time_step_data)\n",
    "    \n",
    "#     # Create a meshgrid for the decision boundary\n",
    "#     x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "#     y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "#     xx, yy = np.meshgrid(np.linspace(x_min, x_max, steps_plot), np.linspace(y_min, y_max, steps_plot))\n",
    "    \n",
    "#     # Flatten the grid to pass through the model\n",
    "#     grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "#     grid_tensor = torch.tensor(pca.inverse_transform(grid), dtype=torch.float32)\n",
    "    \n",
    "#     # Get model predictions for the grid (using the full sequence, assumed to be the same across the grid)\n",
    "#     with torch.no_grad():\n",
    "#         # Repeat the grid tensor to match the time steps of the original data\n",
    "#         grid_tensor_repeated = grid_tensor.unsqueeze(1).repeat(1, all_data.shape[1], 1)\n",
    "#         outputs = model(grid_tensor_repeated)\n",
    "#         z = (outputs[:, -1] > 0.5).float().reshape(xx.shape)  # Use the final time step for decision boundary\n",
    "    \n",
    "#     # Plot the decision boundary\n",
    "#     fig, ax = plt.subplots(figsize=(10, 8))\n",
    "#     ax.contourf(xx, yy, z, cmap=color_map, alpha=0.5)\n",
    "    \n",
    "#     # Plot the data points\n",
    "#     reduced_data_tensor = torch.tensor(reduced_data, dtype=torch.float32)\n",
    "#     outputs = model(all_data.float())\n",
    "#     predicted = (outputs[:, -1] > 0.5).float()  # Use the final time step for predictions\n",
    "    \n",
    "#     # Scatter plot with true labels\n",
    "#     scatter = ax.scatter(reduced_data[:, 0], reduced_data[:, 1], c=all_labels, cmap=color_map, edgecolor='k',alpha=0.1)\n",
    "    \n",
    "#     # Add legend\n",
    "#     legend1 = ax.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "#     ax.add_artist(legend1)\n",
    "\n",
    "#     plt.xlabel('PCA Component 1')\n",
    "#     plt.ylabel('PCA Component 2')\n",
    "#     plt.title('Decision Boundary with PCA-reduced Data')\n",
    "#     plt.show()\n",
    "#     return fig, ax\n",
    "\n",
    "# plot_decision_boundary(model_mlp, test_dataloader, steps=500, steps_plot=500, color_map='Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac040b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SepConv1d(nn.Module):\n",
    "    \"\"\"A simple separable convolution implementation.\n",
    "    \n",
    "    The separable convlution is a method to reduce number of the parameters \n",
    "    in the deep learning network for slight decrease in predictions quality.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(ni, ni, kernel, stride, padding=pad, groups=ni)\n",
    "        self.pointwise = nn.Conv1d(ni, no, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "    \n",
    "class SepConv1d(nn.Module):\n",
    "    \"\"\"Implementes a 1-d convolution with 'batteries included'.\n",
    "    \n",
    "    The module adds (optionally) activation function and dropout \n",
    "    layers right after a separable convolution layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad, \n",
    "                 drop=None, bn=True,\n",
    "                 activ=lambda: nn.PReLU()):\n",
    "    \n",
    "        super().__init__()\n",
    "        assert drop is None or (0.0 < drop < 1.0)\n",
    "        layers = [_SepConv1d(ni, no, kernel, stride, pad)]\n",
    "        if activ:\n",
    "            layers.append(activ())\n",
    "        if bn:\n",
    "            layers.append(nn.BatchNorm1d(no))\n",
    "        if drop is not None:\n",
    "            layers.append(nn.Dropout(drop))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, raw_ni, drop=.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.raw = nn.Sequential(\n",
    "            SepConv1d(raw_ni,  32, 8, 2, 3, drop=drop),\n",
    "            SepConv1d(    32,  32, 3, 1, 1, drop=drop),\n",
    "            SepConv1d(    32,  64, 8, 4, 2, drop=drop),\n",
    "            SepConv1d(    64,  64, 3, 1, 1, drop=drop),\n",
    "            SepConv1d(    64, 128, 8, 4, 2, drop=drop),\n",
    "            SepConv1d(   128, 128, 3, 1, 1, drop=drop),\n",
    "            SepConv1d(   128, 256, 8, 4, 2),\n",
    "            Flatten(),\n",
    "            nn.Dropout(drop), nn.Linear(512, 64), nn.PReLU(), nn.BatchNorm1d(64),\n",
    "            nn.Dropout(drop), nn.Linear( 64, 64), nn.PReLU(), nn.BatchNorm1d(64))\n",
    "        \n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(64, 32), nn.ReLU(inplace=True), nn.Linear(32, 1), nn.Sigmoid())\n",
    "        \n",
    "        self.init_weights(nn.init.kaiming_normal_)\n",
    "        \n",
    "    def init_weights(self, init_fn):\n",
    "        def init(m): \n",
    "            for child in m.children():\n",
    "                if isinstance(child, nn.Conv1d):\n",
    "                    init_fn(child.weights)\n",
    "        init(self)\n",
    "        \n",
    "    def forward(self, t_raw):\n",
    "        t_raw = t_raw\n",
    "        raw_out = self.raw(t_raw)\n",
    "        t_in = raw_out\n",
    "        out = self.output(t_in)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d16e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 16:26:11,062 - INFO - Epoch [1/50], Train Loss: 0.5122, Train Accuracy: 75.95%, Val Loss: 0.5079, Val Accuracy: 75.52%\n",
      "2024-07-31 16:27:33,788 - INFO - Epoch [2/50], Train Loss: 0.5032, Train Accuracy: 76.37%, Val Loss: 0.5213, Val Accuracy: 75.89%\n",
      "2024-07-31 16:28:48,057 - INFO - Epoch [3/50], Train Loss: 0.5004, Train Accuracy: 76.58%, Val Loss: 0.5028, Val Accuracy: 76.12%\n",
      "2024-07-31 16:30:03,315 - INFO - Epoch [4/50], Train Loss: 0.4979, Train Accuracy: 76.62%, Val Loss: 0.5087, Val Accuracy: 75.86%\n",
      "2024-07-31 16:31:18,360 - INFO - Epoch [5/50], Train Loss: 0.4949, Train Accuracy: 76.79%, Val Loss: 0.4950, Val Accuracy: 76.66%\n",
      "2024-07-31 16:32:33,342 - INFO - Epoch [6/50], Train Loss: 0.4932, Train Accuracy: 76.89%, Val Loss: 0.5038, Val Accuracy: 76.07%\n",
      "2024-07-31 16:33:48,358 - INFO - Epoch [7/50], Train Loss: 0.4919, Train Accuracy: 76.92%, Val Loss: 0.4890, Val Accuracy: 76.87%\n",
      "2024-07-31 16:35:05,029 - INFO - Epoch [8/50], Train Loss: 0.4906, Train Accuracy: 76.92%, Val Loss: 0.4990, Val Accuracy: 76.29%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_cnn\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m)\n\u001b[1;32m     11\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m CosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_files/best_cnn_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model_cnn\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_files/best_mlp_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[17], line 53\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience, file_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m early_stopping_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 53\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m validate_one_epoch(model, val_loader, criterion)\n\u001b[1;32m     56\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, labels, _, _ \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[18], line 72\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, t_raw)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t_raw):\n\u001b[1;32m     71\u001b[0m     t_raw \u001b[38;5;241m=\u001b[39m t_raw\n\u001b[0;32m---> 72\u001b[0m     raw_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_raw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     t_in \u001b[38;5;241m=\u001b[39m raw_out\n\u001b[1;32m     74\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(t_in)\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m, in \u001b[0;36mSepConv1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36m_SepConv1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointwise(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepthwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vscodeProjects/arxiv_nlp/arxiv_venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Example usage\n",
    "input_dim = train_dataset.train_window_data.shape[1] #* train_dataset.train_window_data.shape[2] * 2  \n",
    "model_cnn = CNN(input_dim)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.005)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "train_model(model_cnn, train_dataloader, val_dataloader, criterion, optimizer, scheduler,file_name=\"saved_files/best_cnn_model.pth\")\n",
    "model_cnn.load_state_dict(torch.load('saved_files/best_mlp_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cnn.load_state_dict(torch.load('saved_files/best_cnn_model.pth'))\n",
    "plot_roc(model_cnn, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a64c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195159a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_cosine(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "        vec1 (numpy.ndarray): First vector.\n",
    "        vec2 (numpy.ndarray): Second vector.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity between vec1 and vec2.\n",
    "    \"\"\"\n",
    "    cosine_similarity_arr = []\n",
    "    for v1,v2 in zip(vec1, vec2):\n",
    "        cosine_similarity = np.dot(v1, v2)/(np.linalg.norm(v1)* np.linalg.norm(v2))\n",
    "        cosine_similarity_arr.append(cosine_similarity)\n",
    "    return np.array(cosine_similarity_arr)\n",
    "\n",
    "def load_best_model(model, path='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Load the best model from the given path.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to load the state dictionary into.\n",
    "        path (str): Path to the saved model state dictionary.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "def print_predictions(inx_list, label_list, c_inx_arr):\n",
    "    \"\"\"\n",
    "    Print the correct predictions with their slopes.\n",
    "\n",
    "    Args:\n",
    "        correct_list (list): List of correct predictions.\n",
    "        encoding_dat (numpy.ndarray): Encoded data.\n",
    "        c_inx_arr (numpy.ndarray): Concept index array.\n",
    "        label (str): Label for the type of correct prediction (co-occurrence or no co-occurrence).\n",
    "    \"\"\"\n",
    "    # x = np.arange(31).reshape(-1, 1)\n",
    "    # lin_model = LinearRegression()\n",
    "    \n",
    "    for cnt, idx in enumerate(inx_list):\n",
    "        # sim = similarity_cosine(encoding_dat[idx[0]][0].reshape(-1, 1), encoding_dat[idx[1]][0].reshape(-1, 1))\n",
    "        # print(sim.shape)\n",
    "        # lin_model.fit(x, sim.reshape(-1, 1))\n",
    "        # slope = lin_model.coef_[0][0]\n",
    "        print(c_inx_arr[idx[0]], c_inx_arr[idx[1]],  label_list[cnt])\n",
    "        if cnt == 5:\n",
    "            break\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "def evaluate_model_training_concept_predictions(model, dataloader, c_inx_arr):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the provided dataloader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader for the dataset.\n",
    "        encoding_dat (numpy.ndarray): Encoded data.\n",
    "        c_inx_arr (numpy.ndarray): Concept index array.\n",
    "\n",
    "    Returns:\n",
    "        float: Validation accuracy.\n",
    "        numpy.ndarray: Indices of the samples.\n",
    "        numpy.ndarray: Model outputs.\n",
    "        numpy.ndarray: Ground truth labels.\n",
    "        numpy.ndarray: Correct predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct_indices_0 = []\n",
    "    correct_indices_1 = []\n",
    "    correct_labels = []\n",
    "    \n",
    "    false_indices_0 = []\n",
    "    false_indices_1 = []\n",
    "    false_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels, inx_0, inx_1 in dataloader:\n",
    "            \n",
    "            labels = labels.float()\n",
    "            outputs = model(data.float())\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            \n",
    "            pos_inx = (predicted == labels).cpu().numpy().flatten()\n",
    "            neg_inx = (predicted != labels).cpu().numpy().flatten()\n",
    "            \n",
    "            correct_indices_0.append(inx_0[pos_inx].cpu().numpy().flatten() ) \n",
    "            correct_indices_1.append(inx_1[pos_inx].cpu().numpy().flatten() ) \n",
    "\n",
    "            false_indices_0.append(inx_0[neg_inx].cpu().numpy().flatten())\n",
    "            false_indices_1.append(inx_1[neg_inx].cpu().numpy().flatten())\n",
    "\n",
    "            correct_labels.extend(labels[pos_inx].cpu().numpy())\n",
    "            false_labels.extend(labels[neg_inx].cpu().numpy())\n",
    "            \n",
    "            \n",
    "    # Convert lists to numpy arrays\n",
    "    # outputs_list = np.array(outputs_list).flatten()\n",
    "    correct_labels = np.array(correct_labels).flatten()\n",
    "    false_labels = np.array(false_labels).flatten()\n",
    "    correct_indices = np.swapaxes(np.array([flatten(correct_indices_0),flatten(correct_indices_1)]),0,1)\n",
    "    false_indices = np.swapaxes(np.array([flatten(false_indices_0),flatten(false_indices_1)]),0,1)\n",
    "\n",
    "\n",
    "    print(\"False predictions:\")\n",
    "    print_predictions(false_indices, false_labels, c_inx_arr)\n",
    "\n",
    "    print(\"\\nCorrect predictions:\")\n",
    "    print_predictions(correct_indices, correct_labels, c_inx_arr)\n",
    "\n",
    "def evaluate_model_novel_concept_predictions(model, dataloader, c_inx_arr):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the provided dataloader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader for the dataset.\n",
    "        encoding_dat (numpy.ndarray): Encoded data.\n",
    "        c_inx_arr (numpy.ndarray): Concept index array.\n",
    "\n",
    "    Returns:\n",
    "        float: Validation accuracy.\n",
    "        numpy.ndarray: Indices of the samples.\n",
    "        numpy.ndarray: Model outputs.\n",
    "        numpy.ndarray: Ground truth labels.\n",
    "        numpy.ndarray: Correct predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    pos_indices_0 = []\n",
    "    pos_indices_1 = []\n",
    "    neg_indices_0 = []\n",
    "    neg_indices_1 = []\n",
    "    neg_labels = []\n",
    "    pos_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, _, inx_0, inx_1 in dataloader:\n",
    "                        \n",
    "            \n",
    "            outputs = model(data.float())\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            \n",
    "            pos_inx = (predicted == 1).cpu().numpy().flatten()\n",
    "            neg_inx = (predicted == 0).cpu().numpy().flatten()\n",
    "            \n",
    "            pos_indices_0.append(inx_0[pos_inx].cpu().numpy().flatten() ) \n",
    "            pos_indices_1.append(inx_1[pos_inx].cpu().numpy().flatten() ) \n",
    "\n",
    "            neg_indices_0.append(inx_0[neg_inx].cpu().numpy().flatten())\n",
    "            neg_indices_1.append(inx_1[neg_inx].cpu().numpy().flatten())\n",
    "\n",
    "            pos_labels.extend(predicted[pos_inx].cpu().numpy())\n",
    "            neg_labels.extend(predicted[neg_inx].cpu().numpy())\n",
    "            \n",
    "    pos_labels = np.array(pos_labels).flatten()\n",
    "    neg_labels = np.array(neg_labels).flatten()\n",
    "    pos_indices = np.swapaxes(np.array([flatten(pos_indices_0),flatten(pos_indices_1)]),0,1)\n",
    "    neg_indices = np.swapaxes(np.array([flatten(neg_indices_0),flatten(neg_indices_1)]),0,1)\n",
    "            \n",
    "\n",
    "    print(\"Predictions to have no co-occurrence:\")\n",
    "    print_predictions(neg_indices, neg_labels, c_inx_arr)\n",
    "\n",
    "    print(\"\\nPredictions to have co-occurrence:\")\n",
    "    print_predictions(pos_indices, pos_labels, c_inx_arr)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c546c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False predictions:\n",
      "(91640, 2)\n",
      "pure_state_density_matrix shift_operator 0.0\n",
      "robust_quantum_control rayleigh_scattering 1.0\n",
      "quantum_light_source silicon_nitride 1.0\n",
      "quantum_emulation unitary_operation 1.0\n",
      "simulation_optimization photon_blockade 0.0\n",
      "quantum_walk_dynamic gedanken_experiment 0.0\n",
      "\n",
      "Correct predictions:\n",
      "(324860, 2)\n",
      "bound_entangled_state distributed_information_processing 0.0\n",
      "choi_jamiolkowski_isomorphism interferometric_experiment 0.0\n",
      "white_noise quantum_operation 1.0\n",
      "dipole_transition dispersive_qubit_readout 0.0\n",
      "dynamical_invariant thermal_bath 1.0\n",
      "private_quantum_channel network_structure 0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load the best model\n",
    "load_best_model(model_mlp, \"saved_files/best_mlp_model.pth\")\n",
    "\n",
    "# Final evaluation on the validation set\n",
    "evaluate_model_training_concept_predictions(model_mlp, test_dataloader, c_inx_arr)\n",
    "\n",
    "# Analyze predictions\n",
    "# analyze_predictions(indices, outputs_list, labels_list, correct_indices, c_encoding_arr, c_inx_arr)\n",
    "\n",
    "# Print final validation accuracy\n",
    "# logging.info(f\"\\nValidation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bf3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions to have no co-occurrence:\n",
      "(88951, 2)\n",
      "quantum_field_state single_microwave_photon 0.0\n",
      "neural_network_ansatz electron_quantum_dot 0.0\n",
      "optimal_quantum_circuit tunneling_current 0.0\n",
      "entangled_squeezed_state quantum_chaotic_behavior 0.0\n",
      "geometric_quantum_computation information_capacity 0.0\n",
      "pt_symmetric_phase diabatic_state 0.0\n",
      "\n",
      "Predictions to have co-occurrence:\n",
      "(39049, 2)\n",
      "closed_form_formula quantum_volume 1.0\n",
      "nodal_line computational_scaling 1.0\n",
      "canonical_representation light_source 1.0\n",
      "neutron_interferometry quantum_filter 1.0\n",
      "quantum_spin_chain periodically_poled_lithium_niobate_crystal 1.0\n",
      "vibrational_quantum quantum_fourier_transform 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load the best model\n",
    "load_best_model(model_mlp)\n",
    "\n",
    "# Final evaluation on the validation set\n",
    "evaluate_model_novel_concept_predictions(model_mlp, novel_dataloader, c_inx_arr)\n",
    "\n",
    "# Analyze predictions\n",
    "# analyze_novel_predictions(indices, outputs_list, predicted_list, c_encoding_arr, c_inx_arr)\n",
    "\n",
    "# Print final validation accuracy\n",
    "# logging.info(f\"\\nValidation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa963b7",
   "metadata": {},
   "source": [
    "# Top words over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22dbe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.097879  , -5.6156535 , -1.4436402 , -0.7252618 , -2.8818622 ,\n",
       "       -0.1355256 , -1.4049226 ,  1.0180815 , -4.0371447 , -0.5535636 ,\n",
       "       -1.453959  , -3.5074546 ,  0.79714483, -5.212534  , -0.64656687,\n",
       "       -0.4677894 ,  0.295492  ,  2.8346965 , -0.05180334, -0.17619444,\n",
       "        2.4896472 , -5.404429  , -1.3762851 ,  1.8833808 , -0.87085915,\n",
       "        3.9395306 ,  3.9103208 , -7.05772   ,  1.5609605 ,  1.0630037 ,\n",
       "        0.19038764,  1.7278782 ,  4.832178  , 10.330503  , -2.061354  ,\n",
       "       -0.8880872 , -2.2078934 ,  6.377774  , -1.9335837 ,  2.1906054 ,\n",
       "       -3.347395  ,  1.6218128 ,  0.07956028, -2.8315358 , -0.14215828,\n",
       "        0.7692266 ,  2.4328742 ,  2.4729712 ,  4.319967  , -1.3479974 ,\n",
       "       -1.0945354 ,  2.4370947 ,  3.8069773 ,  3.8066788 , -0.822501  ,\n",
       "        0.21370216,  3.233805  ,  1.4806731 , -2.886088  , -3.0978928 ,\n",
       "        0.9960236 , -2.618193  ,  0.69192255,  5.547531  , -2.3263488 ,\n",
       "       -7.104793  , -1.8278835 ,  1.1677247 , -6.2445807 ,  3.4367554 ,\n",
       "       -2.4713356 ,  0.5122792 , -3.626384  ,  0.04576137, -0.6770211 ,\n",
       "        4.185958  ,  1.7242739 ,  0.429511  , -0.3908475 , -2.6018572 ,\n",
       "       -1.578605  ,  0.07406012, -1.7571269 ,  1.3169489 , -5.2286296 ,\n",
       "        4.150717  ,  0.3248223 , -1.6975296 ,  0.76241535, -3.74466   ,\n",
       "        2.203992  ,  3.18234   , -4.190015  , -2.0992193 ,  0.7364317 ,\n",
       "        0.08869237, -3.4841735 ,  0.43545914,  1.5443122 ,  2.2916265 ,\n",
       "        5.5698457 , -2.6219325 ,  0.8610399 , -0.35506663,  1.1861322 ,\n",
       "        0.15618296, -3.7914376 ,  0.5554896 ,  0.7354998 ,  4.1392856 ,\n",
       "        5.4866414 , -4.2503467 ,  1.7930845 ,  3.1497016 ,  4.1394377 ,\n",
       "        3.067325  ,  0.3492784 ,  5.1715426 , -5.0371842 ,  2.363166  ,\n",
       "       -2.5912752 ,  0.89013284,  3.6967611 ,  1.375786  , -3.67276   ,\n",
       "        1.2353942 , -1.3428469 ,  0.63108176], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_w2v.wv.get_vector(\"localized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebeaa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:08:42,580 - INFO - loading Word2Vec object from saved_models/model_year_1994.model\n",
      "2024-07-08 11:08:42,582 - INFO - loading wv recursively from saved_models/model_year_1994.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,583 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,584 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_1994.model', 'datetime': '2024-07-08T11:08:42.584696', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,590 - INFO - loading Word2Vec object from saved_models/model_year_1995.model\n",
      "2024-07-08 11:08:42,594 - INFO - loading wv recursively from saved_models/model_year_1995.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,595 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,603 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_1995.model', 'datetime': '2024-07-08T11:08:42.603507', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,604 - INFO - loading Word2Vec object from saved_models/model_year_1996.model\n",
      "2024-07-08 11:08:42,607 - INFO - loading wv recursively from saved_models/model_year_1996.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,607 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,634 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_1996.model', 'datetime': '2024-07-08T11:08:42.634320', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,640 - INFO - loading Word2Vec object from saved_models/model_year_1997.model\n",
      "2024-07-08 11:08:42,647 - INFO - loading wv recursively from saved_models/model_year_1997.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,649 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,692 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_1997.model', 'datetime': '2024-07-08T11:08:42.692203', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,694 - INFO - loading Word2Vec object from saved_models/model_year_1998.model\n",
      "2024-07-08 11:08:42,700 - INFO - loading wv recursively from saved_models/model_year_1998.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,702 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,761 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_1998.model', 'datetime': '2024-07-08T11:08:42.761829', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,764 - INFO - loading Word2Vec object from saved_models/model_year_1999.model\n",
      "2024-07-08 11:08:42,773 - INFO - loading wv recursively from saved_models/model_year_1999.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,775 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,828 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_1999.model', 'datetime': '2024-07-08T11:08:42.827977', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,829 - INFO - loading Word2Vec object from saved_models/model_year_2000.model\n",
      "2024-07-08 11:08:42,834 - INFO - loading wv recursively from saved_models/model_year_2000.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,835 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,891 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2000.model', 'datetime': '2024-07-08T11:08:42.891175', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,893 - INFO - loading Word2Vec object from saved_models/model_year_2001.model\n",
      "2024-07-08 11:08:42,903 - INFO - loading wv recursively from saved_models/model_year_2001.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,904 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:42,972 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2001.model', 'datetime': '2024-07-08T11:08:42.972698', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:42,973 - INFO - loading Word2Vec object from saved_models/model_year_2002.model\n",
      "2024-07-08 11:08:42,978 - INFO - loading wv recursively from saved_models/model_year_2002.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:42,979 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,036 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2002.model', 'datetime': '2024-07-08T11:08:43.036054', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,037 - INFO - loading Word2Vec object from saved_models/model_year_2003.model\n",
      "2024-07-08 11:08:43,042 - INFO - loading wv recursively from saved_models/model_year_2003.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,043 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,104 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2003.model', 'datetime': '2024-07-08T11:08:43.104695', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,105 - INFO - loading Word2Vec object from saved_models/model_year_2004.model\n",
      "2024-07-08 11:08:43,111 - INFO - loading wv recursively from saved_models/model_year_2004.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,112 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,181 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2004.model', 'datetime': '2024-07-08T11:08:43.181178', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,182 - INFO - loading Word2Vec object from saved_models/model_year_2005.model\n",
      "2024-07-08 11:08:43,189 - INFO - loading wv recursively from saved_models/model_year_2005.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,189 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,261 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2005.model', 'datetime': '2024-07-08T11:08:43.260971', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,262 - INFO - loading Word2Vec object from saved_models/model_year_2006.model\n",
      "2024-07-08 11:08:43,270 - INFO - loading wv recursively from saved_models/model_year_2006.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,271 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,345 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2006.model', 'datetime': '2024-07-08T11:08:43.345917', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,346 - INFO - loading Word2Vec object from saved_models/model_year_2007.model\n",
      "2024-07-08 11:08:43,355 - INFO - loading wv recursively from saved_models/model_year_2007.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,355 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,434 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2007.model', 'datetime': '2024-07-08T11:08:43.434561', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,435 - INFO - loading Word2Vec object from saved_models/model_year_2008.model\n",
      "2024-07-08 11:08:43,441 - INFO - loading wv recursively from saved_models/model_year_2008.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,442 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,526 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2008.model', 'datetime': '2024-07-08T11:08:43.526712', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,527 - INFO - loading Word2Vec object from saved_models/model_year_2009.model\n",
      "2024-07-08 11:08:43,536 - INFO - loading wv recursively from saved_models/model_year_2009.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,536 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,632 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2009.model', 'datetime': '2024-07-08T11:08:43.632824', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,634 - INFO - loading Word2Vec object from saved_models/model_year_2010.model\n",
      "2024-07-08 11:08:43,643 - INFO - loading wv recursively from saved_models/model_year_2010.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,644 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,764 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2010.model', 'datetime': '2024-07-08T11:08:43.764472', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,766 - INFO - loading Word2Vec object from saved_models/model_year_2011.model\n",
      "2024-07-08 11:08:43,774 - INFO - loading wv recursively from saved_models/model_year_2011.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,775 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,873 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2011.model', 'datetime': '2024-07-08T11:08:43.873647', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,874 - INFO - loading Word2Vec object from saved_models/model_year_2012.model\n",
      "2024-07-08 11:08:43,884 - INFO - loading wv recursively from saved_models/model_year_2012.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:43,884 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:43,994 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2012.model', 'datetime': '2024-07-08T11:08:43.994733', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:43,996 - INFO - loading Word2Vec object from saved_models/model_year_2013.model\n",
      "2024-07-08 11:08:44,004 - INFO - loading wv recursively from saved_models/model_year_2013.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:44,005 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:44,114 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2013.model', 'datetime': '2024-07-08T11:08:44.114912', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:44,116 - INFO - loading Word2Vec object from saved_models/model_year_2014.model\n",
      "2024-07-08 11:08:44,124 - INFO - loading wv recursively from saved_models/model_year_2014.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:44,124 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:44,234 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2014.model', 'datetime': '2024-07-08T11:08:44.234853', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:44,236 - INFO - loading Word2Vec object from saved_models/model_year_2015.model\n",
      "2024-07-08 11:08:44,245 - INFO - loading wv recursively from saved_models/model_year_2015.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:44,246 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:44,405 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2015.model', 'datetime': '2024-07-08T11:08:44.405250', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:44,406 - INFO - loading Word2Vec object from saved_models/model_year_2016.model\n",
      "2024-07-08 11:08:44,417 - INFO - loading wv recursively from saved_models/model_year_2016.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:44,418 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:44,551 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2016.model', 'datetime': '2024-07-08T11:08:44.551849', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:44,552 - INFO - loading Word2Vec object from saved_models/model_year_2017.model\n",
      "2024-07-08 11:08:44,564 - INFO - loading wv recursively from saved_models/model_year_2017.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:44,565 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:44,688 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2017.model', 'datetime': '2024-07-08T11:08:44.688347', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:44,689 - INFO - loading Word2Vec object from saved_models/model_year_2018.model\n",
      "2024-07-08 11:08:44,700 - INFO - loading wv recursively from saved_models/model_year_2018.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:44,701 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:44,824 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2018.model', 'datetime': '2024-07-08T11:08:44.824233', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:44,827 - INFO - loading Word2Vec object from saved_models/model_year_2019.model\n",
      "2024-07-08 11:08:44,842 - INFO - loading wv recursively from saved_models/model_year_2019.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:44,842 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:44,985 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2019.model', 'datetime': '2024-07-08T11:08:44.985721', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:44,987 - INFO - loading Word2Vec object from saved_models/model_year_2020.model\n",
      "2024-07-08 11:08:45,005 - INFO - loading wv recursively from saved_models/model_year_2020.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:45,005 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:45,187 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2020.model', 'datetime': '2024-07-08T11:08:45.187339', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:45,188 - INFO - loading Word2Vec object from saved_models/model_year_2021.model\n",
      "2024-07-08 11:08:45,202 - INFO - loading wv recursively from saved_models/model_year_2021.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:45,203 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:45,355 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2021.model', 'datetime': '2024-07-08T11:08:45.355148', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:45,356 - INFO - loading Word2Vec object from saved_models/model_year_2022.model\n",
      "2024-07-08 11:08:45,367 - INFO - loading wv recursively from saved_models/model_year_2022.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:45,368 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:45,501 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2022.model', 'datetime': '2024-07-08T11:08:45.501745', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:45,503 - INFO - loading Word2Vec object from saved_models/model_year_2023.model\n",
      "2024-07-08 11:08:45,515 - INFO - loading wv recursively from saved_models/model_year_2023.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:45,516 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:45,651 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2023.model', 'datetime': '2024-07-08T11:08:45.651930', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n",
      "2024-07-08 11:08:45,653 - INFO - loading Word2Vec object from saved_models/model_year_2024.model\n",
      "2024-07-08 11:08:45,663 - INFO - loading wv recursively from saved_models/model_year_2024.model.wv.* with mmap=None\n",
      "2024-07-08 11:08:45,664 - INFO - setting ignored attribute cum_table to None\n",
      "2024-07-08 11:08:45,807 - INFO - Word2Vec lifecycle event {'fname': 'saved_models/model_year_2024.model', 'datetime': '2024-07-08T11:08:45.807731', 'gensim': '4.3.2', 'python': '3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]', 'platform': 'Linux-6.5.0-41-generic-x86_64-with-glibc2.35', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "year_arr = np.load(\"files/year_arr.npy\", mmap_mode=\"r\")\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "concept_arr = np.unique(np.load(\"files/overlapping_concepts.npy\"))\n",
    "for year in np.unique(year_arr):\n",
    "        \n",
    "    loaded_w2v = Word2Vec.load(\"saved_models/model_year_{}.model\".format(year))\n",
    "\n",
    "    try:\n",
    "        vec_enc = loaded_w2v.wv.get_vector(\"many_body\")\n",
    "        sim = np.array(loaded_w2v.wv.most_similar(\"many_body\"))\n",
    "        print(year)\n",
    "        for s in sim[:,0]:\n",
    "            if s in concept_arr:\n",
    "                print(s)\n",
    "        print(\"\\n\")\n",
    "    except:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n",
      "personal_identification\n",
      "secure_computation\n",
      "private_information\n",
      "quantum_bit_commitment\n",
      "oblivious_transfer\n",
      "class_function\n",
      "quantum_mechanical_consideration\n",
      "\n",
      "\n",
      "1998\n",
      "personal_identification\n",
      "secure_computation\n",
      "private_information\n",
      "quantum_bit_commitment\n",
      "oblivious_transfer\n",
      "class_function\n",
      "quantum_mechanical_consideration\n",
      "algebraic_expression\n",
      "\n",
      "\n",
      "1999\n",
      "personal_identification\n",
      "secure_computation\n",
      "private_information\n",
      "quantum_bit_commitment\n",
      "oblivious_transfer\n",
      "quantum_mechanical_consideration\n",
      "algebraic_expression\n",
      "channel_code\n",
      "cell_structure\n",
      "\n",
      "\n",
      "2000\n",
      "personal_identification\n",
      "secure_computation\n",
      "private_information\n",
      "quantum_bit_commitment\n",
      "quantum_mechanical_consideration\n",
      "algebraic_expression\n",
      "channel_code\n",
      "cell_structure\n",
      "boolean_value\n",
      "\n",
      "\n",
      "2001\n",
      "personal_identification\n",
      "secure_computation\n",
      "private_information\n",
      "quantum_bit_commitment\n",
      "quantum_mechanical_consideration\n",
      "algebraic_expression\n",
      "channel_code\n",
      "cell_structure\n",
      "boolean_value\n",
      "information_theoretic_bound\n",
      "\n",
      "\n",
      "2002\n",
      "personal_identification\n",
      "secure_computation\n",
      "private_information\n",
      "quantum_bit_commitment\n",
      "quantum_mechanical_consideration\n",
      "algebraic_expression\n",
      "channel_code\n",
      "cell_structure\n",
      "boolean_value\n",
      "information_theoretic_bound\n",
      "\n",
      "\n",
      "2003\n",
      "secure_computation\n",
      "private_information\n",
      "personal_identification\n",
      "quantum_mechanical_consideration\n",
      "quantum_bit_commitment\n",
      "algebraic_expression\n",
      "channel_code\n",
      "cell_structure\n",
      "boolean_value\n",
      "nmr_quantum_computer\n",
      "\n",
      "\n",
      "2004\n",
      "secure_computation\n",
      "personal_identification\n",
      "private_information\n",
      "hamming_distance\n",
      "bloch_sphere\n",
      "impedance_function\n",
      "linux_cluster\n",
      "potts_model\n",
      "\n",
      "\n",
      "2005\n",
      "personal_identification\n",
      "private_information\n",
      "secure_computation\n",
      "hamming_distance\n",
      "impedance_function\n",
      "linux_cluster\n",
      "quantum_fingerprinting\n",
      "absorption_experiment\n",
      "quantum_coin_tossing\n",
      "\n",
      "\n",
      "2006\n",
      "personal_identification\n",
      "secure_computation\n",
      "impedance_function\n",
      "linux_cluster\n",
      "absorption_experiment\n",
      "quantum_fingerprinting\n",
      "quantum_coin_tossing\n",
      "partition_function_estimation\n",
      "threshold_scheme\n",
      "\n",
      "\n",
      "2007\n",
      "personal_identification\n",
      "secure_computation\n",
      "impedance_function\n",
      "linux_cluster\n",
      "threshold_scheme\n",
      "absorption_experiment\n",
      "quantum_fingerprinting\n",
      "quantum_coin_tossing\n",
      "partition_function_estimation\n",
      "\n",
      "\n",
      "2008\n",
      "variant_classification\n",
      "partition_function_estimation\n",
      "personal_identification\n",
      "boolean_value\n",
      "hamiltonian_path_problem\n",
      "probabilistic_computing\n",
      "threshold_scheme\n",
      "quantum_state\n",
      "optimal_quantum_cloning\n",
      "\n",
      "\n",
      "2009\n",
      "variant_classification\n",
      "boolean_value\n",
      "optimal_quantum_cloning\n",
      "partition_function_estimation\n",
      "quantum_complexity_theory\n",
      "causal_inference\n",
      "hamiltonian_path_problem\n",
      "personal_identification\n",
      "probabilistic_computing\n",
      "\n",
      "\n",
      "2010\n",
      "boolean_value\n",
      "np_completeness\n",
      "achievable_signal\n",
      "reinforcement_learning\n",
      "characteristic_value\n",
      "sampling_method\n",
      "variant_classification\n",
      "network_computing\n",
      "\n",
      "\n",
      "2011\n",
      "boolean_value\n",
      "reinforcement_learning\n",
      "threshold_electric_field\n",
      "nano_structure\n",
      "state_estimator\n",
      "cell_membrane\n",
      "adjoint_action\n",
      "hamiltonian_path_problem\n",
      "wave_form\n",
      "\n",
      "\n",
      "2012\n",
      "boolean_value\n",
      "nano_structure\n",
      "state_estimator\n",
      "localized_excitation\n",
      "causal_inference\n",
      "\n",
      "\n",
      "2013\n",
      "causal_discovery\n",
      "quantum_perceptron\n",
      "adjoint_action\n",
      "artificial_intelligence\n",
      "\n",
      "\n",
      "2014\n",
      "quantum_perceptron\n",
      "linear_classifier\n",
      "activation_mechanism\n",
      "quantum_finite_automaton\n",
      "quantum_learning\n",
      "quantum_neural_network\n",
      "information_retrieval\n",
      "\n",
      "\n",
      "2015\n",
      "quantum_learning\n",
      "quantum_machine_learning\n",
      "neural_network\n",
      "activation_mechanism\n",
      "linear_classifier\n",
      "rademacher_complexity\n",
      "quantum_information_science\n",
      "quantum_finite_automaton\n",
      "\n",
      "\n",
      "2016\n",
      "quantum_machine_learning\n",
      "quantum_learning\n",
      "artificial_intelligence\n",
      "algorithm_efficiency\n",
      "neural_network\n",
      "binary_search\n",
      "reinforcement_learning\n",
      "gravitational_wave_detection\n",
      "\n",
      "\n",
      "2017\n",
      "quantum_machine_learning\n",
      "generative_model\n",
      "boltzmann_machine\n",
      "quantum_oracle\n",
      "machine_learning_algorithm\n",
      "unsupervised_learning\n",
      "quantum_adiabatic_algorithm\n",
      "\n",
      "\n",
      "2018\n",
      "boltzmann_machine\n",
      "generative_model\n",
      "pattern_recognition\n",
      "quantum_machine_learning\n",
      "machine_learning_algorithm\n",
      "quantum_boltzmann_machine\n",
      "deep_learning\n",
      "neural_network\n",
      "artificial_neural_network\n",
      "\n",
      "\n",
      "2019\n",
      "deep_learning\n",
      "generative_modeling\n",
      "neural_network\n",
      "quantum_machine_learning\n",
      "machine_learning_algorithm\n",
      "artificial_neural_network\n",
      "boltzmann_machine\n",
      "image_recognition\n",
      "generative_model\n",
      "\n",
      "\n",
      "2020\n",
      "quantum_machine_learning\n",
      "generative_modeling\n",
      "deep_learning\n",
      "neural_network\n",
      "artificial_neural_network\n",
      "image_classification\n",
      "binary_classification\n",
      "boltzmann_machine\n",
      "unsupervised_machine_learning\n",
      "\n",
      "\n",
      "2021\n",
      "quantum_machine_learning\n",
      "machine_learning_algorithm\n",
      "deep_learning\n",
      "supervised_learning\n",
      "artificial_neural_network\n",
      "image_classification\n",
      "medical_diagnosis\n",
      "\n",
      "\n",
      "2022\n",
      "quantum_learning\n",
      "quantum_machine_learning\n",
      "machine_learning_algorithm\n",
      "classification_problem\n",
      "unsupervised_learning\n",
      "quantum_support_vector_machine\n",
      "multiclass_classification\n",
      "natural_language_processing\n",
      "\n",
      "\n",
      "2023\n",
      "quantum_machine_learning\n",
      "quantum_machine_learning_algorithm\n",
      "deep_learning\n",
      "quantum_learning\n",
      "natural_language_processing\n",
      "quantum_computing\n",
      "classification_problem\n",
      "inductive_bias\n",
      "\n",
      "\n",
      "2024\n",
      "quantum_machine_learning\n",
      "natural_language_processing\n",
      "quantum_artificial_intelligence\n",
      "deep_learning\n",
      "synaptic_plasticity\n",
      "machine_learning_system\n",
      "neural_network\n",
      "computational_chemistry\n",
      "machine_learning_algorithm\n",
      "artificial_neural_network\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_arr = np.load(\"files/year_arr.npy\", mmap_mode=\"r\")\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "concept_arr = np.unique(np.load(\"files/overlapping_concepts.npy\"))\n",
    "for year in np.unique(year_arr):\n",
    "        \n",
    "    loaded_w2v = Word2Vec.load(\"saved_models/model_year_{}.model\".format(year))\n",
    "\n",
    "    try:\n",
    "        vec_enc = loaded_w2v.wv.get_vector(\"phase_transition\")\n",
    "        sim = np.array(loaded_w2v.wv.most_similar(\"machine_learning\"))\n",
    "        print(year)\n",
    "        for s in sim[:,0]:\n",
    "            if s in concept_arr:\n",
    "                print(s)\n",
    "        print(\"\\n\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the best model\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# # Final evaluation on the validation set\n",
    "# model.eval()\n",
    "# correct_val = 0\n",
    "# total_val = 0\n",
    "\n",
    "# indices = []\n",
    "# outputs_list = []\n",
    "# correct_indices = []\n",
    "# labels_list = []\n",
    "\n",
    "# x = np.arange(31).reshape(-1, 1)\n",
    "# lin_model = LinearRegression()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data, labels, inx in testing_dataloader:\n",
    "#         data = data.view(data.size(0), -1).float()  # Flatten the input data\n",
    "#         labels = labels.float()\n",
    "#         outputs = model(data)\n",
    "#         predicted = (outputs > 0.5).float()\n",
    "#         total_val += labels.size(0)\n",
    "#         correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "#         # Collect indices, outputs, labels, and correct predictions\n",
    "#         indices.extend(inx.cpu().numpy())\n",
    "#         outputs_list.extend(outputs.cpu().numpy())\n",
    "#         labels_list.extend(labels.cpu().numpy())\n",
    "#         correct_indices.extend((predicted == labels).cpu().numpy())\n",
    "        \n",
    "\n",
    "# # Convert lists to numpy arrays for sorting\n",
    "# indices = np.array(indices)\n",
    "# outputs_list = np.array(outputs_list).flatten()\n",
    "# labels_list = np.array(labels_list).flatten()\n",
    "# correct_indices = np.array(correct_indices).flatten()\n",
    "\n",
    "# # Get sorted indices of the outputs\n",
    "# sorted_indices = np.argsort(outputs_list)\n",
    "\n",
    "# # Separate the indices of correct predictions into two categories\n",
    "# correct_0 = []\n",
    "# correct_1 = []\n",
    "\n",
    "# for i in sorted_indices:\n",
    "#     if correct_indices[i]:\n",
    "#         if labels_list[i] == 0:\n",
    "#             correct_0.append(indices[i])\n",
    "#         else:\n",
    "#             correct_1.append(indices[i])\n",
    "\n",
    "# # Print indices of correct predictions\n",
    "# print(\"Correct predictions to have no co-occurance:\")\n",
    "# for cnt,idx in enumerate(correct_0):\n",
    "#     sim = similarity_cosine(encoding_dat[idx[0]][0],encoding_dat[idx[1]][0])\n",
    "#     lin_model.fit(x, sim.reshape(-1, 1))\n",
    "#     slope = lin_model.coef_[0][0]\n",
    "#     print(c_inx_arr[idx[0]],c_inx_arr[idx[1]], np.round(slope,3))\n",
    "#     if cnt ==5:\n",
    "#         break\n",
    "\n",
    "# print(\"\\n Correct predictions to have co-occurance:\")\n",
    "# for cnt,idx in enumerate(correct_1):\n",
    "#     sim = similarity_cosine(encoding_dat[idx[0]][0],encoding_dat[idx[1]][0])\n",
    "#     lin_model.fit(x, sim.reshape(-1, 1))\n",
    "#     slope = lin_model.coef_[0][0]\n",
    "#     print(c_inx_arr[idx[0]],c_inx_arr[idx[1]], np.round(slope,3))\n",
    "#     if cnt ==5:\n",
    "#         break\n",
    "\n",
    "# print(f\"\\nValidation Accuracy: {100 * correct_val / total_val:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e527d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the best model\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# # Final evaluation on the validation set\n",
    "# model.eval()\n",
    "# correct_val = 0\n",
    "# total_val = 0\n",
    "\n",
    "# indices = []\n",
    "# outputs_list = []\n",
    "# predicted_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data, inx in novel_dataloader:\n",
    "#         data = data.view(data.size(0), -1).float()  # Flatten the input data\n",
    "        \n",
    "#         outputs = model(data)\n",
    "#         predicted = (outputs > 0.5).float()\n",
    "        \n",
    "#         # Collect indices, outputs, labels, and correct predictions\n",
    "#         indices.extend(inx.cpu().numpy())\n",
    "#         outputs_list.extend(outputs.cpu().numpy())\n",
    "#         predicted_list.extend(predicted.cpu().numpy())\n",
    "        \n",
    "# # Convert lists to numpy arrays for sorting\n",
    "# indices = np.array(indices)\n",
    "# outputs_list = np.array(outputs_list).flatten()\n",
    "# predicted_list = np.array(predicted_list).flatten()\n",
    "\n",
    "\n",
    "# # Get sorted indices of the outputs\n",
    "# sorted_indices = np.argsort(outputs_list)\n",
    "\n",
    "# # Separate the indices of correct predictions into two categories\n",
    "# correct_0 = []\n",
    "# correct_1 = []\n",
    "\n",
    "# for i in sorted_indices:\n",
    "#     if predicted_list[i]:\n",
    "#         correct_1.append(indices[i])\n",
    "#     else:\n",
    "#         correct_0.append(indices[i])\n",
    "\n",
    "# # Print indices of correct predictions\n",
    "# print(\" Predictions to have no co-occurance:\")\n",
    "# for cnt,idx in enumerate(correct_0):\n",
    "#     sim = similarity_cosine(encoding_dat[idx[0]][0],encoding_dat[idx[1]][0])\n",
    "#     lin_model.fit(x, sim.reshape(-1, 1))\n",
    "#     slope = lin_model.coef_[0][0]\n",
    "#     print(c_inx_arr[idx[0]],c_inx_arr[idx[1]], np.round(slope,3))\n",
    "#     if cnt ==5:\n",
    "#         break\n",
    "\n",
    "# print(\"\\n Predictions to have co-occurance:\")\n",
    "# for cnt,idx in enumerate(correct_1):\n",
    "#     sim = similarity_cosine(encoding_dat[idx[0]][0],encoding_dat[idx[1]][0])\n",
    "#     lin_model.fit(x, sim.reshape(-1, 1))\n",
    "#     slope = lin_model.coef_[0][0]\n",
    "#     print(c_inx_arr[idx[0]],c_inx_arr[idx[1]],np.round(slope,3))\n",
    "#     if cnt ==5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BaselineDataset(Dataset):\n",
    "#     def __init__(self, data: np.ndarray, word_co_occurrences: dict, year_arr: np.ndarray, c_inx_arr: np.ndarray, \n",
    "#                  input_window_size: int = 5, output_window_size: int = 3, offset_to_current_year: int = 1):\n",
    "#         \"\"\"\n",
    "#         Dataset for time series data.\n",
    "\n",
    "#         Args:\n",
    "#             data (np.ndarray): The input data.\n",
    "#             word_co_occurrences (dict): Dictionary of word co-occurrences.\n",
    "#             year_arr (np.ndarray): Array of years.\n",
    "#             c_inx_arr (np.ndarray): Array of concept indices.\n",
    "#             input_window_size (int, optional): Size of the input window. Defaults to 5.\n",
    "#             output_window_size (int, optional): Size of the output window. Defaults to 3.\n",
    "#             offset_to_current_year (int, optional): Offset to the current year. Defaults to 1.\n",
    "#         \"\"\"\n",
    "#         self.train_window_data = data[:, -input_window_size-output_window_size-offset_to_current_year:-output_window_size-offset_to_current_year]\n",
    "#         self.label_year_range = (year_arr[-output_window_size:] if offset_to_current_year == 0 \n",
    "#                                  else year_arr[-output_window_size-offset_to_current_year:-offset_to_current_year])\n",
    "\n",
    "#         self.co_occur_concept_pair_arr = self.get_co_occur_concept_pair_after_year_arr(\n",
    "#             word_co_occurrences, self.label_year_range[0], self.label_year_range[-1])\n",
    "#         self.c_inx_arr = c_inx_arr\n",
    "#         self.input_window_size = input_window_size\n",
    "#         self.output_window_size = output_window_size\n",
    "#         self.offset_to_current_year = offset_to_current_year\n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         return 64 * 5000\n",
    "\n",
    "#     def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "#         return (self._get_positive_sample() if np.random.rand() < 0.5 else self._get_negative_sample())\n",
    "\n",
    "#     def _get_positive_sample(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "#         while True:\n",
    "#             sampled_pairs = np.random.choice(len(self.co_occur_concept_pair_arr), size=1)\n",
    "#             c_pair = self.co_occur_concept_pair_arr[sampled_pairs][0]\n",
    "#             inx_0 = np.where(self.c_inx_arr == c_pair[0])[0]\n",
    "#             inx_1 = np.where(self.c_inx_arr == c_pair[1])[0]\n",
    "#             if inx_0.size > 0 and inx_1.size > 0:\n",
    "#                 break\n",
    "#         enc_0 = self.train_window_data[inx_0][0][-1,:]\n",
    "#         enc_1 = self.train_window_data[inx_1][0][-1,:]\n",
    "        \n",
    "#         return torch.from_numpy(enc_0), torch.from_numpy(enc_1),  torch.ones(1), torch.from_numpy(np.array([inx_0, inx_1]))\n",
    "\n",
    "#     def _get_negative_sample(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "#         while True:\n",
    "#             sampled_pair = np.random.choice(self.train_window_data.shape[0], size=2)\n",
    "#             if self.c_inx_arr[sampled_pair[1]] not in word_co_occurrences[self.c_inx_arr[sampled_pair[0]]]:\n",
    "#                 break\n",
    "#         inx_0 = np.where(self.c_inx_arr == self.c_inx_arr[sampled_pair[0]])[0]\n",
    "#         inx_1 = np.where(self.c_inx_arr == self.c_inx_arr[sampled_pair[1]])[0]\n",
    "#         enc_0 = self.train_window_data[inx_0][0][-1,:]\n",
    "#         enc_1 = self.train_window_data[inx_1][0][-1,:]\n",
    "        \n",
    "#         return torch.from_numpy(enc_0), torch.from_numpy(enc_1), torch.zeros(1), torch.from_numpy(np.array([inx_0, inx_1]))\n",
    "\n",
    "#     def _check_indexing(self):\n",
    "#         print(f\"Training Window: {self._get_years_range(-self.input_window_size-self.output_window_size-self.offset_to_current_year, -self.output_window_size-self.offset_to_current_year)}\")\n",
    "#         print(f\"Label Window: {self._get_years_range(-self.output_window_size-self.offset_to_current_year, -self.offset_to_current_year)}\")\n",
    "\n",
    "#     def _get_years_range(self, start: int, end: int) -> np.ndarray:\n",
    "#         # return np.unique(saved_year_arr)[start:end]\n",
    "    \n",
    "#         return (np.unique(saved_year_arr)[start:] if end == -0 \n",
    "#                                  else np.unique(saved_year_arr)[start:end])\n",
    "\n",
    "#     @staticmethod\n",
    "#     def get_co_occur_concept_pair_after_year_arr(word_co_occurrences: dict, first_occ_year: int, final_occ_year: int) -> np.ndarray:\n",
    "        \n",
    "#         co_occur_concept_pair_arr = []\n",
    "#         for concept, v in word_co_occurrences.items():\n",
    "#             for co_concept, years in v.items():\n",
    "#                 if np.min(years) >= first_occ_year and np.max(years)<=final_occ_year:\n",
    "#                     co_occur_concept_pair_arr.append([concept,co_concept])\n",
    "#         return np.array(co_occur_concept_pair_arr)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# num_samples_per_class = 32\n",
    "# num_features = 128\n",
    "# seq_length = 10\n",
    "# out_length = 3\n",
    "# batch_size = 128\n",
    "\n",
    "# print(\"Representation Vectors for tracked concepts\",c_encoding_arr.shape)\n",
    "# print(\"Concept associted with representation\", c_inx_arr.shape)\n",
    "# scaler = RobustScaler()\n",
    "# reshaped_data = c_encoding_arr.reshape(-1, c_encoding_arr.shape[-1])  # Shape: (10000*31, 128)\n",
    "# normalized_data = scaler.fit_transform(reshaped_data)\n",
    "# encoding_data = normalized_data.reshape(c_encoding_arr.shape)\n",
    "\n",
    "# dataset_baseline = BaselineDataset(data=encoding_data, word_co_occurrences=word_co_occurrences, year_arr=np.unique(saved_year_arr), \n",
    "#                             c_inx_arr=c_inx_arr, input_window_size = seq_length, output_window_size = out_length, offset_to_current_year = 3)\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# val_size = len(dataset_baseline) - train_size\n",
    "# train_baseline_dataset, val_baseline_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# train_baseline_loader = DataLoader(train_baseline_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_baseline_loader = DataLoader(val_baseline_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# testing_baseline_dataset = BaselineDataset(data=encoding_data, word_co_occurrences=word_co_occurrences, year_arr=np.unique(saved_year_arr), \n",
    "#                             c_inx_arr=c_inx_arr, input_window_size = seq_length, output_window_size = out_length, offset_to_current_year = 0)\n",
    "# testing_baseline_dataset._check_indexing()\n",
    "# testing_baseline_dataloader = DataLoader(testing_baseline_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a856d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CosineSimilarityModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CosineSimilarityModel, self).__init__()\n",
    "\n",
    "#     def forward(self, vec1, vec2):\n",
    "#         # Ensure the input vectors are of the same shape\n",
    "#         assert vec1.shape == vec2.shape, \"Input vectors must have the same shape\"\n",
    "        \n",
    "#         # Compute cosine similarity\n",
    "#         # cosine_similarity = F.cosine_similarity(vec1, vec2, dim=-1)\n",
    "#         elementwise_product = vec1 * vec2\n",
    "\n",
    "#         # Sum along the feature dimension (dim=1)\n",
    "#         cosine_similarity = elementwise_product.sum(dim=1)\n",
    "        \n",
    "#         return cosine_similarity\n",
    "\n",
    "# class CosineSimilarityClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CosineSimilarityClassifier, self).__init__()\n",
    "#         self.cos_sim_model = CosineSimilarityModel()\n",
    "\n",
    "#     def forward(self, vec1, vec2):\n",
    "#         # Compute cosine similarity\n",
    "#         cosine_similarity = self.cos_sim_model(vec1, vec2)\n",
    "        \n",
    "#         # Rescale cosine similarity from [-1, 1] to [0, 1]\n",
    "#         rescaled_similarity = (cosine_similarity + 1) / 2\n",
    "        \n",
    "#         # Binary classification (class 1 if similarity >= 0.5, else class 0)\n",
    "        \n",
    "        \n",
    "#         return rescaled_similarity\n",
    "\n",
    "\n",
    "# model_cos = CosineSimilarityClassifier()\n",
    "\n",
    "# all_preds = []\n",
    "# all_labels = []\n",
    "# all_probs = []\n",
    "# all_precision = []\n",
    "# all_rand_precision = []\n",
    "\n",
    "\n",
    "# for cnt, (enc_0, enc_1, labels, _) in enumerate(testing_baseline_dataloader):\n",
    "#     enc_0 = enc_0.float()\n",
    "#     enc_1 = enc_1.float()\n",
    "    \n",
    "#     labels = labels.float()\n",
    "    \n",
    "    \n",
    "#     outputs = model_cos(enc_0, enc_1).view(-1,1)\n",
    "\n",
    "    \n",
    "    \n",
    "#     probs = outputs.cpu().numpy()\n",
    "#     predicted = (outputs > 0.5).float()\n",
    "#     precision_ = precision_score(labels,predicted)\n",
    "    \n",
    "#     precision_rand = precision_score(labels,np.random.randint(0,2,len(predicted)))\n",
    "    \n",
    "#     all_probs.extend(probs)\n",
    "#     all_preds.extend(predicted.cpu().numpy())\n",
    "#     all_labels.extend(labels.cpu().numpy())\n",
    "#     all_precision.extend([precision_])\n",
    "#     all_rand_precision.extend([precision_rand])\n",
    "    \n",
    "#     if cnt == 1000:\n",
    "#         break\n",
    "\n",
    "# # Convert lists to numpy arrays\n",
    "# all_preds = np.array(all_preds).flatten()\n",
    "# all_labels = np.array(all_labels).flatten()\n",
    "# all_probs = np.array(all_probs).flatten()\n",
    "\n",
    "# # Calculate confusion matrix\n",
    "# conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# # Print confusion matrix\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "# plt.xlabel('Predicted Labels')\n",
    "# plt.ylabel('True Labels')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate ROC curve and AUC\n",
    "# fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Plot ROC curve\n",
    "# plt.figure(figsize=(3.5, 3))\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
