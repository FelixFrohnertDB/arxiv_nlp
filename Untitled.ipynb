{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b06eeb-b7bc-4787-a65f-de3ef301bd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/vscodeProjects/arXiv/arxiv_venv/lib/python3.9/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline\n",
    "from rake_nltk import Rake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f0e73d-8e47-420b-8987-d654445f49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"abcde(ab(abcde)abcde)abcde\"\n",
    "\n",
    "\n",
    "def findOccurrences(s, ch):\n",
    "    return [i for i, letter in enumerate(s) if letter == ch]\n",
    "\n",
    "def remove_latex_math_formulas(text):\n",
    "    # Remove formulas enclosed in $...$\n",
    "    pattern_single = r\"\\$.*?\\$\"\n",
    "    text = re.sub(pattern_single, \"<lTx>\", text)\n",
    "    \n",
    "    # Remove formulas enclosed in $$...$$\n",
    "    pattern_double = r\"\\$\\$.*?\\$\\$\"\n",
    "    text = re.sub(pattern_double, \"<lTx>\", text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700ae633-ddd8-45b9-932b-3a2722ec4d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6307, 8235, 49638, 150302)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_arr = ['submitter','authors', 'comments', 'journal-ref', 'doi', 'report-no', 'license', 'versions', 'update_date', 'authors_parsed']\n",
    "\n",
    "indicator_arr_1 = [\"announcement\",\"bookreview\", \"erratum\", \"editorialnotes\", \"news\", \"events\", \"acknowledgement\", \"supplement\"]\n",
    "indicator_arr_2 = [\"Foreword\",\"Prelude\", \"Commentary\", \"Workshop\", \"Conference\", \"Symposium\", \"Comment\", \"Retract\", \"Correction\", \"Memorial\"]\n",
    "\n",
    "cnt_1 = 0 \n",
    "cnt_2 = 0 \n",
    "cnt_3 = 0 \n",
    "cnt_quant = 0\n",
    "cnt_test = 0 \n",
    "with open('arxiv.csv','w', newline='') as file:\n",
    "    for line in open(\"arxiv-metadata-oai-snapshot.json\", 'r'): \n",
    "        cnt_test += 1 \n",
    "        \n",
    "\n",
    "        temp = json.loads(line) \n",
    "\n",
    "        # if cnt_test < 561764:\n",
    "        #     # print(temp)\n",
    "        #     continue\n",
    "           \n",
    "        if \"quant\" in temp[\"categories\"]:\n",
    "            cnt_quant += 1 \n",
    "\n",
    "            if cnt_quant %10000 == 0 :\n",
    "                print(cnt_quant)\n",
    "            \n",
    "            if any(ext in str(temp).lower() for ext in indicator_arr_1):\n",
    "                cnt_1 += 1 \n",
    "                continue \n",
    "            else:\n",
    "                temp[\"abstract\"] = temp[\"abstract\"].replace(\"\\n\",\" \")\n",
    "                temp[\"abstract\"] = temp[\"abstract\"].replace(\",\",\"\")\n",
    "                temp[\"abstract\"] = temp[\"abstract\"].replace(\"'\",\"\")\n",
    "                temp[\"abstract\"] = temp[\"abstract\"].replace('\\\"o','o')\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                if \"$$\" in temp[\"abstract\"] or \"$\" in temp[\"abstract\"] or \"\\\\\" in temp[\"abstract\"]:\n",
    "                    cnt_3 += 1 \n",
    "                    temp[\"abstract\"] = re.sub(r\"(\\$+)(?:(?!\\1)[\\s\\S])*\\1\", \"<lTx>\", temp[\"abstract\"])\n",
    "                \n",
    "                if \"[\" in temp[\"abstract\"] and \"]\" in temp[\"abstract\"]:\n",
    "                    cnt_2 += 1 \n",
    "                    temp[\"abstract\"] = re.sub(r\"\\[.*?\\]\", \"<bRa>\", temp[\"abstract\"])\n",
    "    \n",
    "                if \"{\" in temp[\"abstract\"] and \"}\" in temp[\"abstract\"]:\n",
    "                    cnt_3 += 1 \n",
    "\n",
    "                    temp[\"abstract\"] = re.sub(r\"\\{.*?\\}\", \"<bRa>\", temp[\"abstract\"])\n",
    "\n",
    "                                    \n",
    "                for del_item in del_arr:\n",
    "                    del temp[del_item]\n",
    "                \n",
    "                save_txt = \"{},{},{}\".format(str(temp[\"id\"]),re.sub(\"[^A-Za-z.<>]+\", ' ', str(temp[\"title\"])).lower(),re.sub(\"[^A-Za-z.<>]+\", ' ', str(temp[\"abstract\"])).lower()  )\n",
    "\n",
    "                \n",
    "                file.write(save_txt)\n",
    "                file.write('\\n')\n",
    "\n",
    "                \n",
    "cnt_1, cnt_2, cnt_3, cnt_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa6a7c9-8e7e-480d-9863-814219d533b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('arxiv.csv',names=[\"id\",\"title\",\"abstract\"])\n",
    "ab_arr = df[\"abstract\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63cdfef-c360-4f9a-a3a7-082628bb6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake(min_length=2,max_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ffda9f-653f-40d4-956f-7c34aa78b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('concept.csv','w', newline='') as file:\n",
    "    for abstract in df[\"abstract\"].to_numpy():\n",
    "        # print(abstract)\n",
    "        r.extract_keywords_from_text(abstract)\n",
    "        arr = r.get_ranked_phrases_with_scores()\n",
    "        try:\n",
    "            concept_arr = np.array(list(dict.fromkeys(arr))[:3])[:,1]\n",
    "        except:\n",
    "            concept_arr = []\n",
    "            \n",
    "            \n",
    "        if len(concept_arr) == 0:\n",
    "            file.write(\"\")\n",
    "        if len(concept_arr) == 1:\n",
    "            file.write(concept_arr[0])\n",
    "        if len(concept_arr) == 2:\n",
    "            file.write(concept_arr[0]+\",\"+concept_arr[1])\n",
    "        if len(concept_arr) == 3:\n",
    "            file.write(concept_arr[0]+\",\"+concept_arr[1]+\",\"+concept_arr[2])\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454480e9-fbea-443b-a4e4-8235d408a40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ddded-f960-49e8-ad23-967f78b225de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bfcad-499c-4f9d-bf34-35cabbc85dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493f099-8755-4835-8cac-7f6dd05aa6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe706efe-6bf9-470d-abd9-2cf5a6c2a6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f2728-f4c5-4252-9935-e099861938fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d56819-123c-49a7-b7ed-db0cf3af333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('arxiv.csv',names=[\"id\",\"title\",\"abstract\"])\n",
    "\n",
    "# openai.api_key = \"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\"\n",
    "\n",
    "# def chat_with_gpt(prompt):\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         temperature=0.5,\n",
    "#         n=1,\n",
    "#         max_tokens=100\n",
    "#     )\n",
    "\n",
    "#     # Get the reply from the model\n",
    "#     reply = response.choices[0].message['content']\n",
    "#     return reply\n",
    "\n",
    "# cnt = 0 \n",
    "# with open('8_word.csv','w', newline='') as file:\n",
    "#     for abstract in df[\"abstract\"]: \n",
    "        \n",
    "#         if cnt % 100==0:\n",
    "#             print(cnt)\n",
    "#         cnt += 1\n",
    "#         if cnt < 2233:\n",
    "#             continue \n",
    "        \n",
    "#         prompt = 'The following text contains a surprising result. Can you identify what the surprising result refers to and restrict your answer to a single sentence? ' + '\"' + abstract+'\"'\n",
    "#         reply = chat_with_gpt(prompt)#.message[\"content\"]\n",
    "#         file.write(reply)\n",
    "#         file.write('\\n')\n",
    "#         time.sleep(20)  \n",
    "\n",
    "# import csv\n",
    "\n",
    "# sentences = []\n",
    "# with open(\"1_word.csv\", \"r\") as csvfile:\n",
    "#     reader = csv.reader(csvfile)\n",
    "#     for row in reader:\n",
    "#         sentences.append(row[0])\n",
    "\n",
    "# # Convert the list of sentences to a NumPy array\n",
    "# np_sentences = np.array(sentences)\n",
    "\n",
    "# # Print the NumPy array\n",
    "# #print(np_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "424b7208-1e46-427b-bea2-f065071b0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bertopic import BERTopic\n",
    "\n",
    "# topic_model = BERTopic(verbose=True, embedding_model=\"paraphrase-MiniLM-L12-v2\", min_topic_size=20)\n",
    "# topics, _ = topic_model.fit_transform(np_sentences); len(topic_model.get_topic_info())\n",
    "# topic_model.get_topic_info().head(10)\n",
    "# topic_model.visualize_barchart(top_n_topics=8, width=300)\n",
    "# topic_model.visualize_topics(top_n_topics=50)\n",
    "# topic_model.visualize_hierarchy(top_n_topics=50, width=800)\n",
    "# topic_model.visualize_heatmap(n_clusters=5, top_n_topics=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff89de4-d805-49dd-a264-f97875961219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485d364-5408-46eb-9b25-4fbb109dfc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d14c1-0f37-49c8-b10d-33d57d94971f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b44ff-6f05-4cf7-8919-fa00545cd708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58673d69-05f2-4f00-afaa-5684ec22d6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36234e0-6ae9-4952-9778-a9c52e3beb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81e22e-252e-4581-903e-5ea7197bb442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
