{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b06eeb-b7bc-4787-a65f-de3ef301bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.phrases import Phraser\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39eefd",
   "metadata": {},
   "source": [
    "Our goal is now to take the preprocessed abstracts and identify the physics concepts within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d81e22e-252e-4581-903e-5ea7197bb442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66839\n"
     ]
    }
   ],
   "source": [
    "df_arx = pd.read_csv('saved_files/arxiv_preprocessed.csv',names=[\"id\",\"abstract\",\"date\"])\n",
    "ab_arr = df_arx[\"abstract\"].to_numpy()\n",
    "print(len(ab_arr))\n",
    "df_arx[\"date\"] = pd.to_datetime(df_arx[\"date\"])\n",
    "year_arr = df_arx['date'].dt.year.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfa720",
   "metadata": {},
   "source": [
    "As an example, this is a abstract after the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc066fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'possible construct closed quantum system governed bilinear hamiltonian depending arbitrary input signal achieved coupling quantum input field performing feedback output field cancel stochastic effect signal added field event later subtracted assume zero time delay limit connection operation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(ab_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b27ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atomic = pd.read_csv('saved_files/arxiv_atomic_concept.txt',names=[\"con\"])\n",
    "atomic_arr = np.array([con for con in df_atomic[\"con\"].to_numpy()])\n",
    "\n",
    "df_optic = pd.read_csv('saved_files/arxiv_optics_concept.txt',names=[\"con\"])\n",
    "optic_arr = np.array([con for con in df_optic[\"con\"].to_numpy()])\n",
    "\n",
    "df_quantum = pd.read_csv('saved_files/arxiv_quantum_concept.txt',names=[\"con\"])\n",
    "quantum_arr = np.array([con for con in df_quantum[\"con\"].to_numpy()])\n",
    "\n",
    "concept_compare_arr = np.unique(np.concatenate((atomic_arr,optic_arr,quantum_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61bb550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66839/66839 [00:10<00:00, 6674.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create keyword lookup dictionary\n",
    "keyword_lookup = defaultdict(list)\n",
    "for keyword in concept_compare_arr:\n",
    "    keyword_lookup[keyword].append(keyword)\n",
    "\n",
    "# List to store modified abstracts\n",
    "modified_ab_arr = []\n",
    "matched_concepts = []\n",
    "\n",
    "# Iterate through abstracts\n",
    "for ab in tqdm(ab_arr):\n",
    "    ab_tokens = ab.split()\n",
    "    modified_ab_tokens = []\n",
    "    i = 0\n",
    "    while i < len(ab_tokens):\n",
    "        found_sequence = False\n",
    "        for j in range(6, 0, -1):  # Try different lengths of sequences in descending order\n",
    "            if i + j <= len(ab_tokens):\n",
    "                seq_tokens = ab_tokens[i:i + j]\n",
    "                seq_ = ' '.join(seq_tokens)\n",
    "                if seq_ in keyword_lookup:\n",
    "                    for keyword in keyword_lookup[seq_]:\n",
    "                        modified_ab_tokens.append('_'.join(seq_tokens))\n",
    "                        matched_concepts.append(keyword.replace(' ', '_'))\n",
    "                    i += j  # Move to the next position after the matched sequence\n",
    "                    found_sequence = True\n",
    "                    break\n",
    "        if not found_sequence:\n",
    "            modified_ab_tokens.append(ab_tokens[i])\n",
    "            i += 1\n",
    "    modified_ab_arr.append(' '.join(modified_ab_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdeda0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24302, 33420)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(matched_concepts).shape[0], concept_compare_arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed95f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66839/66839 [00:00<00:00, 270506.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10235"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_word_count_subset(corpus, subset_words):\n",
    "    for document in tqdm(corpus):\n",
    "        for word in document:\n",
    "            if word in subset_words:\n",
    "                subset_words[word] += 1\n",
    "    return subset_words\n",
    "\n",
    "# Compute word count for the subset of words \n",
    "word_count_subset = compute_word_count_subset([row.split() for row in modified_ab_arr], {k:0 for k in np.unique(matched_concepts)})\n",
    "\n",
    "cnt = 0 \n",
    "filtered_arr = []\n",
    "for k,v in word_count_subset.items():\n",
    "    if v > 4:\n",
    "        cnt += 1 \n",
    "        filtered_arr.append(k)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41517d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"saved_files/ngram_abstracts.npy\",modified_ab_arr)\n",
    "np.save(\"saved_files/overlapping_filtered_5_concepts.npy\",np.unique(filtered_arr))\n",
    "np.save(\"saved_files/year_arr.npy\",year_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
