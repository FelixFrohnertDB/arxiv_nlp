{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b06eeb-b7bc-4787-a65f-de3ef301bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39eefd",
   "metadata": {},
   "source": [
    "Our goal is now to take the preprocessed 148564 abstracts and identify the physics concepts within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d81e22e-252e-4581-903e-5ea7197bb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arx = pd.read_csv('files/arxiv_stop.csv',names=[\"id\",\"abstract\",\"date\", \"s_indc\"])\n",
    "ab_arr = df_arx[\"abstract\"].to_numpy()\n",
    "df_arx[\"date\"] = pd.to_datetime(df_arx[\"date\"])\n",
    "year_arr = df_arx['date'].dt.year.to_numpy()\n",
    "month_arr = df_arx['date'].dt.month.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306d511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148564"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ab_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfa720",
   "metadata": {},
   "source": [
    "As an example, this is a abstract after the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc066fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   a property of a system be call actual if the observation of the test that pertain to that property yield an affirmation with certainty we formalize the act of observation by assume that the outcome correlate with the state of the observed system and be codify as an actual property of the state of the observer at the end of the measurement interaction for an actual property the observe outcome have to affirm that property with certainty hence in this case the correlation need to be perfect a property be call classical if either the property or its negation be actual it be show by a diagonal argument that there exist classical property of an observer that he can not observe perfectly because state be identify with the collection of property that be actual for that state it follow that no observer can perfectly observe his own state implication for the quantum measurement problem be briefly discuss'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(ab_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec0878",
   "metadata": {},
   "source": [
    "This is the part where the second important design decision is made: \n",
    "The word2vec model we want to use later can only handle individual words.\n",
    "In order to be able to process physics abstracts, which might contain more than one individual word, we want to represent them as n-grams.\n",
    "I.e. the processed text should contain \"schroedinger_equation\" and not \"schroedinger\",\"equation\".\n",
    "\n",
    "gensim has a function which extracts common n-grams (max:4) from the text, given a min_count of 10 and some threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df6af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(sentences):\n",
    "    \"\"\" Detects n-grams with n up to 4, and replaces those in the abstracts. \"\"\"\n",
    "    # Train a 2-word (bigram) phrase-detector\n",
    "    bigram_phrases = gensim.models.phrases.Phrases(sentences,min_count=10,threshold=15)\n",
    "    \n",
    "    # And construct a phraser from that (an object that will take a sentence\n",
    "    # and replace in it the bigrams that it knows by single objects)\n",
    "    bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "    \n",
    "    # Repeat that for trigrams; the input now are the bigrammed-titles\n",
    "    ngram_phrases = gensim.models.phrases.Phrases(bigram[sentences],min_count=10,threshold=15)\n",
    "    ngram         = gensim.models.phrases.Phraser(ngram_phrases)\n",
    "    \n",
    "    # !! If you want to have more than 4-grams, just repeat the structure of the\n",
    "    #    above two lines. That is, train another Phrases on the ngram_phrases[titles],\n",
    "    #    that will get you up to 8-grams. \n",
    "    \n",
    "    # Now that we have phrasers for bi- and trigrams, let's analyze them\n",
    "    # The phrases.export_phrases(x) function returns pairs of phrases and their\n",
    "    # certainty scores from x.\n",
    "    bigram_info = {}\n",
    "    for b, score in bigram_phrases.export_phrases().items():\n",
    "        bigram_info[b] = [score, bigram_info.get(b,[0,0])[1] + 1]\n",
    "        \n",
    "    ngram_info = {}\n",
    "    for b, score in ngram_phrases.export_phrases().items():\n",
    "        ngram_info[b] = [score, ngram_info.get(b,[0,0])[1] + 1]\n",
    "            \n",
    "    # Return a list of 'n-grammed' abtracts, and the bigram and trigram info\n",
    "    return [ngram[t] for t in sentences], bigram_info, ngram_info\n",
    "\n",
    "sentences = [row.split() for row in ab_arr]\n",
    "ngram_abstracts, bigrams, ngrams = get_ngrams(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce88ad4",
   "metadata": {},
   "source": [
    "This gives us a list of 10565 ngrams which contain physics concepts as well as some natural language we are not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "472ba5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10565"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b236bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['representability_condition', 'non_prime', 'species_selective',\n",
       "       'nnn_hopping', 'wigner_friend', 'off_resonantly', 'wave_packet',\n",
       "       'self_kerr', 'nucleon_nucleon', 'secure_key_leasing'], dtype='<U54')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(list(ngrams.keys()),size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e084e54",
   "metadata": {},
   "source": [
    "We now load a given list of suitable physics concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9179800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atomic = pd.read_csv('files/arxiv_atomic_concept.txt',names=[\"con\"])\n",
    "atomic_arr = np.array([con.replace(\" \", \"_\") for con in df_atomic[\"con\"].to_numpy()])\n",
    "\n",
    "df_optic = pd.read_csv('files/arxiv_optics_concept.txt',names=[\"con\"])\n",
    "optic_arr = np.array([con.replace(\" \", \"_\") for con in df_optic[\"con\"].to_numpy()])\n",
    "\n",
    "df_quantum = pd.read_csv('files/arxiv_quantum_concept.txt',names=[\"con\"])\n",
    "quantum_arr = np.array([con.replace(\" \", \"_\") for con in df_quantum[\"con\"].to_numpy()])\n",
    "\n",
    "concept_compare_arr = np.unique(np.concatenate((atomic_arr,optic_arr,quantum_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3cd0a",
   "metadata": {},
   "source": [
    "and do a naive preprecess, where we check if there are some direct matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788d2021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  2716 entries directly\n",
      "Check  30703 further\n"
     ]
    }
   ],
   "source": [
    "pre_selec_inx = np.array([c in ngrams for c in concept_compare_arr]).astype(int)\n",
    "concept_pre_compare_arr = concept_compare_arr[pre_selec_inx==1]\n",
    "concept_continue_compare_arr = concept_compare_arr[pre_selec_inx==0]\n",
    "print(\"Found \",concept_pre_compare_arr.shape[0],\"entries directly\") \n",
    "print(\"Check \",concept_continue_compare_arr.shape[0],\"further\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91b48a",
   "metadata": {},
   "source": [
    "The goal now is to find ngrams with an overlap with a concept which exceeds some threshold.\n",
    "\n",
    "With this, we want to catch concepts which only differ in their grammar slightly, or contain an additional word.\n",
    "\n",
    "For simplicity, I chose \"partial_token_sort_ratio\", which simply compares the letters in both strings to be compared. \n",
    "There probably exists a better choice here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458b3836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping Concepts: [['quantum_phase_transition' 'phase_transition' '81']\n",
      " ['electron' 'electron_hole' '100']]\n",
      "Non-Overlapping Concepts: ['other_concept' 'other_concept_<']\n"
     ]
    }
   ],
   "source": [
    "def find_overlapping_concepts(concepts1, concepts2, threshold=80):\n",
    "    # concepts1 are the various ngrams that were extracted with no regard about physics\n",
    "    # concepts2 are the physics concepts we are in general interested in\n",
    "    # Goal of this function is to compare the overlap, at a given threshhold the concept is assumed to match\n",
    "    overlapping_concepts = []\n",
    "    non_overlapping_concepts = []\n",
    "\n",
    "    for concept1 in concepts1:\n",
    "        match = False \n",
    "        if \"<\" in concept1 or \">\" in concept1:\n",
    "            non_overlapping_concepts.append(concept1)\n",
    "            continue \n",
    "\n",
    "        for concept2 in concepts2:\n",
    "\n",
    "            # Use fuzz ratio to measure similarity\n",
    "            \n",
    "            similarity_ratio = fuzz.partial_token_sort_ratio(concept1, concept2)\n",
    "           \n",
    "            # Adjust the threshold based on your requirements\n",
    "            if similarity_ratio >= threshold and len(concept1)>3:\n",
    "                overlapping_concepts.append((concept1, concept2, similarity_ratio))\n",
    "                match = True \n",
    "                break \n",
    "        if not match:\n",
    "            non_overlapping_concepts.append(concept1) \n",
    "\n",
    "    return np.array(overlapping_concepts), np.array(non_overlapping_concepts)\n",
    "\n",
    "# # Example usage:\n",
    "concept_list1 = [\"quantum_phase_transition\", \"electron\", \"other_concept\",\"other_concept_<\"]\n",
    "concept_list2 = [\"phase_transition\", \"electron_hole\", \"another_concept\"]\n",
    "\n",
    "result = find_overlapping_concepts(concept_list1, concept_list2)\n",
    "print(\"Overlapping Concepts:\", result[0])\n",
    "print(\"Non-Overlapping Concepts:\", result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad3bfa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8925, 3), (1640,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs in about 6 minutes \n",
    "check_arr = np.array(list(ngrams.keys()))\n",
    "overlapping_concepts, non_overlapping_concepts = find_overlapping_concepts(check_arr,concept_continue_compare_arr,threshold=80)\n",
    "overlapping_concepts.shape, non_overlapping_concepts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feae4d5",
   "metadata": {},
   "source": [
    "Print a few overlapping concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95088c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relationship_between' 'non_linear_relationship' '82']\n",
      "['truth_value' 'ct_value' '88']\n",
      "['arrive_at' 'arrival_time_delay' '80']\n",
      "['relative_entropy' 'entropy_equation' '80']\n",
      "['density_matrix' 'coefficient_matrix' '83']\n",
      "['per_unit' 'circular_unit' '86']\n",
      "['fascinating_phenomenon' 'gibbs_phenomenon' '86']\n",
      "['basic_idea' 'adiabatic_demagnetization' '80']\n",
      "['arise_naturally' 'natural_bias' '83']\n",
      "['travel_wave' 'alfven_wave' '80']\n",
      "['lamb_dicke_limit' 'band_limit' '82']\n",
      "['jaynes_cumming_model' 'abc_model' '80']\n",
      "['rotate_wave' 'achromatic_half_wave_plate' '84']\n",
      "['rotate_wave_approximation' 'edge_wave' '80']\n",
      "['non_rwa' 'energy_transfer_phenomenon' '86']\n",
      "['spin_dependent' 'dependent_source' '88']\n",
      "['trap_ion' 'adiabatic_population_transfer' '88']\n",
      "['difference_between' 'absolute_difference' '84']\n",
      "['information_processing' 'advanced_quantum_information_processing' '100']\n",
      "['quantum_information_processing'\n",
      " 'advanced_quantum_information_processing' '100']\n",
      "['time_dependent' 'dependent_source' '83']\n",
      "['harmonic_oscillator' 'anharmonic_oscillator_equation' '81']\n",
      "['et_al' 'abnormal_behavior' '80']\n",
      "['exponentially_decay' 'decay_mode' '82']\n",
      "['expand_universe' 'closed_universe' '85']\n",
      "['geometric_phase' 'ac_phase' '93']\n",
      "['circular_birefringence' 'circular_arc' '87']\n",
      "['unified_picture' 'unified_field' '82']\n",
      "['base_on' 'base_field' '83']\n",
      "['angular_momentum' 'abraham_momentum' '81']\n",
      "['suitable_choice' 'bi_stable' '80']\n"
     ]
    }
   ],
   "source": [
    "for cnt,_ in enumerate(overlapping_concepts):\n",
    "    print(_)\n",
    "    if cnt == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfeb9fb",
   "metadata": {},
   "source": [
    "Print a few non-overlapping concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6216016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bisognano_wichmann', 'not_necessarily', 'critically_examine',\n",
       "       'worst_case_scenario', 'fulde_ferrell_<bra>',\n",
       "       'realignment_criterion', 'down_convert', 'gallium_arsenide',\n",
       "       'almost_all', 'most_important', 'su_<bra>', 'weakly_perturb',\n",
       "       'd_=', 'merlin_arthur', 'freely_expand', 'ramsey_fringe',\n",
       "       'leggett_type', 'do_not_contribute', 'affleck_kennedy_lieb_tasaki',\n",
       "       'most_importantly', 'few_dozen', 'loschmidt_echo_<bra>', 'i_d',\n",
       "       'closely_analogous', 'delegate_her', 'year_ago', '<num>_hz',\n",
       "       'liu_et_al', 'the_aharonov_casher', 'rigorously_prove'],\n",
       "      dtype='<U48')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(non_overlapping_concepts,size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91999edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"files/overlapping_save_concepts.npy\",np.unique(np.concatenate((overlapping_concepts[:,0],concept_pre_compare_arr))))\n",
    "np.save(\"files/non_overlapping_save_concepts.npy\",non_overlapping_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f427c70",
   "metadata": {},
   "source": [
    "This gives us 9000 ngrams of which we now assume that they are valid physics concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3b2223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.concatenate((overlapping_concepts[:,0],concept_pre_compare_arr))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30014c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_abstracts_repl = ngram_abstracts.copy()\n",
    "words_to_replace_set = set(non_overlapping_concepts)\n",
    "cnt = 0 \n",
    "for sublist in ngram_abstracts:\n",
    "    for i in range(len(sublist)):\n",
    "        if sublist[i] in words_to_replace_set:\n",
    "            sublist[i] = sublist[i].replace(\"_\", \" \")\n",
    "            cnt += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d864c",
   "metadata": {},
   "source": [
    "We remove the non_overlapping_concepts by replacing \"_\" with \" \" in 9827 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd034f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112534"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e57e31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"files/ngram_abstracts_repl.npy\",[' '.join(ab) for ab in ngram_abstracts_repl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60cea8b",
   "metadata": {},
   "source": [
    "Print some n-grams to check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb320e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top bigrams by certainty:\n",
      " 1: whisper_gallery                                    \t(49019608.00) \n",
      " 3: fabry_perot                                        \t(20610517.00) \n",
      " 6: gell_mann                                          \t(14854426.67) \n",
      " 7: retro_reflecte                                     \t(13368984.00) \n",
      "10: henon_heile                                        \t(11140820.00) \n",
      "11: vice_versa                                         \t(10787143.17) \n",
      "16: jaynes_cumming                                     \t(6183155.10) \n",
      "18: majumdar_ghosh                                     \t(6127451.00) \n",
      "22: diffie_hellman                                     \t(3713606.67) \n",
      "23: poschl_teller                                      \t(3416518.13) \n",
      "24: reissner_nordstrom                                 \t(3342246.00) \n",
      "27: coarse_graining                                    \t(3062297.19) \n",
      "28: korteweg_de_vrie                                   \t(2847098.44) \n",
      "29: randall_sundrum                                    \t(2785205.00) \n",
      "33: autler_towne                                       \t(2450980.40) \n",
      "34: stern_gerlach                                      \t(2254689.76) \n",
      "35: ping_pong                                          \t(2228164.00) \n",
      "37: ab_initio                                          \t(2163344.68) \n",
      "40: monte_carlo                                        \t(1924032.42) \n",
      "41: kohn_sham                                          \t(1767999.70) \n"
     ]
    }
   ],
   "source": [
    "phys_conc = set(np.unique(np.concatenate((overlapping_concepts[:,0],concept_pre_compare_arr))))\n",
    "\n",
    "sortedns  = sorted( [(ngrams[b][0], ngrams[b][1], b) for b in ngrams.keys()] )[::-1]\n",
    "print(\"Top bigrams by certainty:\")\n",
    "i = 0 \n",
    "cnt = 0 \n",
    "while cnt < 20:\n",
    "    if sortedns[i][2] in phys_conc:\n",
    "        print(\"{0:2}: {1:50} \\t({2}) \".format(i+1, str(sortedns[i][2]), \"%.2f\"%sortedns[i][0]))\n",
    "        cnt += 1 \n",
    "    i+= 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e396ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least certain bigrams:\n",
      " 1: three_partite                                      \t(15.00) \n",
      " 3: security_guarantee                                 \t(15.00) \n",
      " 4: wigner_friend_scenario                             \t(15.00) \n",
      " 5: micro_ring_resonator                               \t(15.01) \n",
      " 6: relation_between                                   \t(15.01) \n",
      " 7: maximally_entangle_state                           \t(15.01) \n",
      " 8: relativistic_covariance                            \t(15.01) \n",
      " 9: post_selection_procedure                           \t(15.02) \n",
      "10: highly_entangled                                   \t(15.02) \n",
      "12: singular_value_transformation                      \t(15.03) \n",
      "13: majorana_bind                                      \t(15.03) \n",
      "14: phase_shift                                        \t(15.03) \n",
      "15: tripartite_ghz                                     \t(15.03) \n",
      "18: completely_destroy                                 \t(15.05) \n",
      "20: entanglement_witness                               \t(15.05) \n",
      "21: multi_photon_excitation                            \t(15.06) \n",
      "23: nonunitary_evolution                               \t(15.06) \n",
      "26: much_small                                         \t(15.07) \n",
      "27: de_donder_weyl                                     \t(15.07) \n",
      "28: dc_current                                         \t(15.07) \n"
     ]
    }
   ],
   "source": [
    "phys_conc = set(np.unique(np.concatenate((overlapping_concepts[:,0],concept_pre_compare_arr))))\n",
    "\n",
    "sortedns  = sorted( [(ngrams[b][0], ngrams[b][1], b) for b in ngrams.keys()] )#[::-1]\n",
    "print(\"Least certain bigrams:\")\n",
    "i = 0 \n",
    "cnt = 0 \n",
    "while cnt < 20:\n",
    "    if sortedns[i][2] in phys_conc:\n",
    "        print(\"{0:2}: {1:50} \\t({2}) \".format(i+1, str(sortedns[i][2]), \"%.2f\"%sortedns[i][0]))\n",
    "        cnt += 1 \n",
    "    i+= 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
